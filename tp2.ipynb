{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from _datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "product_headers_to_encode = ['PRODUCTTYPENAME', 'ROUTENAME', 'DOSAGEFORMNAME', 'MARKETINGCATEGORYNAME',\n",
    "                             'ACTIVE_NUMERATOR_STRENGTH', 'ACTIVE_INGRED_UNIT']\n",
    "package_headers_to_encode = ['PACKAGEDESCRIPTION']\n",
    "\n",
    "standard_dosageformname = {\"AEROSOL\": \"AEROSOL\", \"AEROSOL, FOAM\": \"AEROSOL\", \"AEROSOL, METERED\": \"AEROSOL\",\n",
    "                           \"AEROSOL, POWDER\": \"AEROSOL\", \"AEROSOL, SPRAY\": \"AEROSOL\", \"BAR\": \"BAR\",\n",
    "                           \"BAR, CHEWABLE\": \"BAR\", \"BEAD\": \"BEAD\", \"CAPSULE\": \"CAPSULE\", \"CAPSULE, COATED\": \"CAPSULE\",\n",
    "                           \"CAPSULE, COATED PELLETS\": \"CAPSULE\", \"CAPSULE, COATED, EXTENDED RELEASE\": \"CAPSULE\",\n",
    "                           \"CAPSULE, DELAYED RELEASE\": \"CAPSULE\", \"CAPSULE, DELAYED RELEASE PELLETS\": \"CAPSULE\",\n",
    "                           \"CAPSULE, EXTENDED RELEASE\": \"CAPSULE\", \"CAPSULE, FILM COATED, EXTENDED RELEASE\": \"CAPSULE\",\n",
    "                           \"CAPSULE, GELATIN COATED\": \"CAPSULE\", \"CAPSULE, LIQUID FILLED\": \"CAPSULE\",\n",
    "                           \"CELLULAR SHEET\": \"CELLULAR SHEET\", \"CHEWABLE GEL\": \"CHEWABLE GEL\", \"CLOTH\": \"CLOTH\",\n",
    "                           \"CONCENTRATE\": \"CONCENTRATE\", \"CREAM\": \"CREAM\", \"CREAM, AUGMENTED\": \"CREAM\",\n",
    "                           \"CRYSTAL\": \"CRYSTAL\", \"DISC\": \"DISC\", \"DOUCHE\": \"DOUCHE\", \"DRESSING\": \"DRESSING\",\n",
    "                           \"ELIXIR\": \"ELIXIR\", \"EMULSION\": \"EMULSION\", \"ENEMA\": \"ENEMA\", \"EXTRACT\": \"EXTRACT\",\n",
    "                           \"FIBER, EXTENDED RELEASE\": \"FIBER\", \"FILM\": \"FILM\", \"FILM, EXTENDED RELEASE\": \"FILM\",\n",
    "                           \"FILM, SOLUBLE\": \"FILM\", \"FOR SOLUTION\": \"FOR SOLUTION\", \"FOR SUSPENSION\": \"FOR SUSPENSION\",\n",
    "                           \"FOR SUSPENSION, EXTENDED RELEASE\": \"FOR SUSPENSION\", \"GAS\": \"GAS\", \"GEL\": \"GEL\",\n",
    "                           \"GEL, DENTIFRICE\": \"GEL\", \"GEL, METERED\": \"GEL\", \"GLOBULE\": \"GLOBULE\", \"GRANULE\": \"GRANULE\",\n",
    "                           \"GRANULE, DELAYED RELEASE\": \"GRANULE\", \"GRANULE, EFFERVESCENT\": \"GRANULE\",\n",
    "                           \"GRANULE, FOR SOLUTION\": \"GRANULE\", \"GRANULE, FOR SUSPENSION\": \"GRANULE\",\n",
    "                           \"GRANULE, FOR SUSPENSION, EXTENDED RELEASE\": \"GRANULE\", \"GUM\": \"GUM\", \"GUM, CHEWING\": \"GUM\",\n",
    "                           \"IMPLANT\": \"IMPLANT\", \"INHALANT\": \"INHALANT\", \"INJECTABLE FOAM\": \"INJECTABLE FOAM\",\n",
    "                           \"INJECTABLE\": \"INJECTABLE\", \"INJECTABLE, LIPOSOMAL\": \"INJECTABLE\", \"INJECTION\": \"INJECTION\",\n",
    "                           \"INJECTION, EMULSION\": \"INJECTION\", \"INJECTION, LIPID COMPLEX\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, FOR SOLUTION\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, FOR SUSPENSION\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, FOR SUSPENSION, EXTENDED RELEASE\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, LYOPHILIZED, FOR LIPOSOMAL SUSPENSION\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, LYOPHILIZED, FOR SOLUTION\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, LYOPHILIZED, FOR SUSPENSION\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, LYOPHILIZED, FOR SUSPENSION, EXTENDED RELEASE\": \"INJECTION\",\n",
    "                           \"INJECTION, SOLUTION\": \"INJECTION\", \"INJECTION, SOLUTION, CONCENTRATE\": \"INJECTION\",\n",
    "                           \"INJECTION, SUSPENSION\": \"INJECTION\", \"INJECTION, SUSPENSION, EXTENDED RELEASE\": \"INJECTION\",\n",
    "                           \"INJECTION, SUSPENSION, LIPOSOMAL\": \"INJECTION\",\n",
    "                           \"INJECTION, SUSPENSION, SONICATED\": \"INJECTION\", \"INSERT\": \"INSERT\",\n",
    "                           \"INSERT, EXTENDED RELEASE\": \"INSERT\", \"INTRAUTERINE DEVICE\": \"INTRAUTERINE DEVICE\",\n",
    "                           \"IRRIGANT\": \"IRRIGANT\", \"JELLY\": \"JELLY\", \"KIT\": \"KIT\", \"LINIMENT\": \"LINIMENT\",\n",
    "                           \"LIPSTICK\": \"LIPSTICK\", \"LIQUID\": \"LIQUID\", \"LIQUID, EXTENDED RELEASE\": \"LIQUID\",\n",
    "                           \"LOTION\": \"LOTION\", \"LOTION, AUGMENTED\": \"LOTION\", \"LOTION/SHAMPOO\": \"LOTION/SHAMPOO\",\n",
    "                           \"LOZENGE\": \"LOZENGE\", \"MOUTHWASH\": \"MOUTHWASH\", \"NOT APPLICABLE\": \"NOT APPLICABLE\",\n",
    "                           \"OIL\": \"OIL\", \"OINTMENT\": \"OINTMENT\", \"OINTMENT, AUGMENTED\": \"OINTMENT\", \"PASTE\": \"PASTE\",\n",
    "                           \"PASTE, DENTIFRICE\": \"PASTE\", \"PASTILLE\": \"PASTILLE\", \"PATCH\": \"PATCH\",\n",
    "                           \"PATCH, EXTENDED RELEASE\": \"PATCH\",\n",
    "                           \"PATCH, EXTENDED RELEASE, ELECTRICALLY CONTROLLED\": \"PATCH\", \"PELLET\": \"PELLET\",\n",
    "                           \"PELLET, IMPLANTABLE\": \"PELLET\", \"PELLETS, COATED, EXTENDED RELEASE\": \"PELLETS\",\n",
    "                           \"PILL\": \"PILL\", \"PLASTER\": \"PLASTER\", \"POULTICE\": \"POULTICE\", \"POWDER\": \"POWDER\",\n",
    "                           \"POWDER, DENTIFRICE\": \"POWDER\", \"POWDER, FOR SOLUTION\": \"POWDER\",\n",
    "                           \"POWDER, FOR SUSPENSION\": \"POWDER\", \"POWDER, METERED\": \"POWDER\", \"RING\": \"RING\",\n",
    "                           \"RINSE\": \"RINSE\", \"SALVE\": \"SALVE\", \"SHAMPOO\": \"SHAMPOO\", \"SHAMPOO, SUSPENSION\": \"SHAMPOO\",\n",
    "                           \"SOAP\": \"SOAP\", \"SOLUTION\": \"SOLUTION\", \"SOLUTION, CONCENTRATE\": \"SOLUTION\",\n",
    "                           \"SOLUTION, FOR SLUSH\": \"SOLUTION\", \"SOLUTION, GEL FORMING / DROPS\": \"SOLUTION\",\n",
    "                           \"SOLUTION, GEL FORMING, EXTENDED RELEASE\": \"SOLUTION\", \"SOLUTION/ DROPS\": \"SOLUTION/ DROPS\",\n",
    "                           \"SPONGE\": \"SPONGE\", \"SPRAY\": \"SPRAY\", \"SPRAY, METERED\": \"SPRAY\",\n",
    "                           \"SPRAY, SUSPENSION\": \"SPRAY\", \"STICK\": \"STICK\", \"STRIP\": \"STRIP\",\n",
    "                           \"SUPPOSITORY\": \"SUPPOSITORY\", \"SUPPOSITORY, EXTENDED RELEASE\": \"SUPPOSITORY\",\n",
    "                           \"SUSPENSION\": \"SUSPENSION\", \"SUSPENSION, EXTENDED RELEASE\": \"SUSPENSION\",\n",
    "                           \"SUSPENSION/ DROPS\": \"SUSPENSION/ DROPS\", \"SWAB\": \"SWAB\", \"SYRUP\": \"SYRUP\",\n",
    "                           \"SYSTEM\": \"SYSTEM\", \"TABLET\": \"TABLET\", \"TABLET, CHEWABLE\": \"TABLET\",\n",
    "                           \"TABLET, CHEWABLE, EXTENDED RELEASE\": \"TABLET\", \"TABLET, COATED\": \"TABLET\",\n",
    "                           \"TABLET, COATED PARTICLES\": \"TABLET\", \"TABLET, DELAYED RELEASE\": \"TABLET\",\n",
    "                           \"TABLET, DELAYED RELEASE PARTICLES\": \"TABLET\", \"TABLET, EFFERVESCENT\": \"TABLET\",\n",
    "                           \"TABLET, EXTENDED RELEASE\": \"TABLET\", \"TABLET, FILM COATED\": \"TABLET\",\n",
    "                           \"TABLET, FILM COATED, EXTENDED RELEASE\": \"TABLET\", \"TABLET, FOR SOLUTION\": \"TABLET\",\n",
    "                           \"TABLET, FOR SUSPENSION\": \"TABLET\", \"TABLET, MULTILAYER\": \"TABLET\",\n",
    "                           \"TABLET, MULTILAYER, EXTENDED RELEASE\": \"TABLET\", \"TABLET, ORALLY DISINTEGRATING\": \"TABLET\",\n",
    "                           \"TABLET, ORALLY DISINTEGRATING, DELAYED RELEASE\": \"TABLET\", \"TABLET, SOLUBLE\": \"TABLET\",\n",
    "                           \"TABLET, SUGAR COATED\": \"TABLET\", \"TABLET WITH SENSOR\": \"TABLET WITH SENSOR\",\n",
    "                           \"TAMPON\": \"TAMPON\", \"TAPE\": \"TAPE\", \"TINCTURE\": \"TINCTURE\", \"TROCHE\": \"TROCHE\",\n",
    "                           \"WAFER\": \"WAFER\"}\n",
    "standard_routename = [\"AURICULAR (OTIC)\", \"BUCCAL\", \"CONJUNCTIVAL\", \"CUTANEOUS\", \"DENTAL\", \"ELECTRO-OSMOSIS\",\n",
    "                      \"ENDOCERVICAL\", \"ENDOSINUSIAL\", \"ENDOTRACHEAL\", \"ENTERAL\", \"EPIDURAL\", \"EXTRA-AMNIOTIC\",\n",
    "                      \"EXTRACORPOREAL\", \"HEMODIALYSIS\", \"INFILTRATION\", \"INTERSTITIAL\", \"INTRA-ABDOMINAL\",\n",
    "                      \"INTRA-AMNIOTIC\", \"INTRA-ARTERIAL\", \"INTRA-ARTICULAR\", \"INTRABILIARY\", \"INTRABRONCHIAL\",\n",
    "                      \"INTRABURSAL\", \"INTRACANALICULAR\", \"INTRACARDIAC\", \"INTRACARTILAGINOUS\", \"INTRACAUDAL\",\n",
    "                      \"INTRACAVERNOUS\", \"INTRACAVITARY\", \"INTRACEREBRAL\", \"INTRACISTERNAL\", \"INTRACORNEAL\",\n",
    "                      \"INTRACORONAL, DENTAL\", \"INTRACORONARY\", \"INTRACORPORUS CAVERNOSUM\", \"INTRACRANIAL\",\n",
    "                      \"INTRADERMAL\", \"INTRADISCAL\", \"INTRADUCTAL\", \"INTRADUODENAL\", \"INTRADURAL\", \"INTRAEPICARDIAL\",\n",
    "                      \"INTRAEPIDERMAL\", \"INTRAESOPHAGEAL\", \"INTRAGASTRIC\", \"INTRAGINGIVAL\", \"INTRAHEPATIC\",\n",
    "                      \"INTRAILEAL\", \"INTRALESIONAL\", \"INTRALINGUAL\", \"INTRALUMINAL\", \"INTRALYMPHATIC\", \"INTRAMAMMARY\",\n",
    "                      \"INTRAMEDULLARY\", \"INTRAMENINGEAL\", \"INTRAMUSCULAR\", \"INTRANODAL\", \"INTRAOCULAR\", \"INTRAOMENTUM\",\n",
    "                      \"INTRAOVARIAN\", \"INTRAPERICARDIAL\", \"INTRAPERITONEAL\", \"INTRAPLEURAL\", \"INTRAPROSTATIC\",\n",
    "                      \"INTRAPULMONARY\", \"INTRARUMINAL\", \"INTRASINAL\", \"INTRASPINAL\", \"INTRASYNOVIAL\", \"INTRATENDINOUS\",\n",
    "                      \"INTRATESTICULAR\", \"INTRATHECAL\", \"INTRATHORACIC\", \"INTRATUBULAR\", \"INTRATUMOR\", \"INTRATYMPANIC\",\n",
    "                      \"INTRAUTERINE\", \"INTRAVASCULAR\", \"INTRAVENOUS\", \"INTRAVENTRICULAR\", \"INTRAVESICAL\",\n",
    "                      \"INTRAVITREAL\", \"IONTOPHORESIS\", \"IRRIGATION\", \"LARYNGEAL\", \"NASAL\", \"NASOGASTRIC\",\n",
    "                      \"NOT APPLICABLE\", \"OCCLUSIVE DRESSING TECHNIQUE\", \"OPHTHALMIC\", \"ORAL\", \"OROPHARYNGEAL\",\n",
    "                      \"PARENTERAL\", \"PERCUTANEOUS\", \"PERIARTICULAR\", \"PERIDURAL\", \"PERINEURAL\", \"PERIODONTAL\", \"RECTAL\",\n",
    "                      \"RESPIRATORY (INHALATION)\", \"RETROBULBAR\", \"SOFT TISSUE\", \"SUBARACHNOID\", \"SUBCONJUNCTIVAL\",\n",
    "                      \"SUBCUTANEOUS\", \"SUBGINGIVAL\", \"SUBLINGUAL\", \"SUBMUCOSAL\", \"SUBRETINAL\", \"TOPICAL\", \"TRANSDERMAL\",\n",
    "                      \"TRANSENDOCARDIAL\", \"TRANSMUCOSAL\", \"TRANSPLACENTAL\", \"TRANSTRACHEAL\", \"TRANSTYMPANIC\",\n",
    "                      \"URETERAL\", \"URETHRAL\", \"VAGINAL\"]\n",
    "standard_marketingcategoryname = [\"ANADA\", \"ANDA\", \"Approved Drug Product Manufactured Under Contract\", \"BLA\",\n",
    "                                  \"Bulk ingredient\", \"Bulk Ingredient For Animal Drug Compounding\",\n",
    "                                  \"Bulk Ingredient For Human Prescription Compounding\", \"Conditional NADA\", \"Cosmetic\",\n",
    "                                  \"Dietary Supplement\", \"Drug for Further Processing\", \"Exempt device\", \"Export only\",\n",
    "                                  \"Humanitarian Device Exemption\", \"IND\", \"Medical Food\",\n",
    "                                  \"Legally Marketed Unapproved New Animal Drugs for Minor Species\", \"NADA\", \"NDA\",\n",
    "                                  \"NDA authorized generic\", \"OTC Monograph Drug Product Manufactured Under Contract\",\n",
    "                                  \"OTC monograph final\", \"OTC monograph not final\", \"Premarket Application\",\n",
    "                                  \"Premarket Notification\", \"Unapproved drug for use in drug shortage\",\n",
    "                                  \"Unapproved drug other\", \"Unapproved Drug Product Manufactured Under Contract\",\n",
    "                                  \"Unapproved homeopathic\", \"Unapproved medical gas\"]\n",
    "standard_deaschedule = [\"CI\", \"CII\", \"CIII\", \"CIV\", \"CV\"]\n",
    "standard_ndcexcludeflag = [\"N\"]\n",
    "\n",
    "target_encoding = 'utf-8'\n",
    "separ = '|'\n",
    "custom_sep = ' ?[|,;:<>] ?|^ | $'\n",
    "\n",
    "product_file = 'Product2.csv'\n",
    "package_file = 'Package2.csv'\n",
    "\n",
    "encoder_dir = 'encoders/'\n",
    "encoding_dir = 'enconding_dic/'\n",
    "\n",
    "encoded_product_file = 'transformed_product_data.csv'\n",
    "encoded_package_file = 'transformed_package_data.csv'\n",
    "\n",
    "product_encode_file_exist = False\n",
    "package_encode_file_exist = False\n",
    "\n",
    "# TODO incohernce entre dates\n",
    "# TODO incohernce entre routname / forme\n",
    "# TODO incohernce entre valeurs numeric abberantes (ordre de grandeur)\n",
    "# TODO incohernce entre valeurs phase et l'emballage\n",
    "# TODO tester imputatin itérative\n",
    "\n",
    "def assert_table_completeness(table):\n",
    "    empty_cells = table.shape[0] - table.count(axis=0)\n",
    "    unique_values = table.nunique(axis=0)\n",
    "\n",
    "    print('Empty cells:\\n{}\\n'.format(empty_cells))\n",
    "    print('Unique values:\\n{}\\n'.format(unique_values))\n",
    "\n",
    "\n",
    "def assert_product_id_completeness(table, header):\n",
    "    empty_cells = table.shape[0] - table.count(axis=0)\n",
    "    unique_values = table.nunique(axis=0)\n",
    "\n",
    "    if empty_cells[header] == 0:\n",
    "        print('No empty values in the {} column'.format(header))\n",
    "    else:\n",
    "        print('There are {} empty values in the {} column'.format(empty_cells[header], header))\n",
    "\n",
    "    if unique_values[header] == table.shape[0]:\n",
    "        print('No duplicat values in the {} column'.format(header))\n",
    "    else:\n",
    "        print(\n",
    "            'There are {} duplicat values in the {} column\\n\\n'.format(table.shape[0] - unique_values[header], header))\n",
    "\n",
    "\n",
    "def get_unique_values(table, headers=''):\n",
    "    uniques = {}\n",
    "    if headers == '':\n",
    "        cols = table.columns.values\n",
    "        for n, c in enumerate(cols):\n",
    "            uniques[c] = pd.unique(table[c])\n",
    "    elif type(headers) is list:\n",
    "        for header in headers:\n",
    "            uniques[header] = pd.unique(table[header])\n",
    "    elif type(headers) is str:\n",
    "        uniques[headers] = pd.unique(table[headers])\n",
    "    return uniques\n",
    "\n",
    "\n",
    "def df_to_lower(table, columns='all'):\n",
    "    cols = table.columns.values if columns == 'all' else columns\n",
    "    for c in cols:\n",
    "        try:\n",
    "            table[c] = table[c].str.lower()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "def get_decomposed_uniques(table, header):\n",
    "    decomposed_uniques = {}\n",
    "    if type(header) is str:\n",
    "        for unique_header, uniques in get_unique_values(table, header).items():\n",
    "            tmp_lst = []\n",
    "            for val in uniques:\n",
    "                if type(val) is str:\n",
    "                    for decomposed in re.split(custom_sep, val):\n",
    "                        if decomposed != '' and not decomposed in tmp_lst:\n",
    "                            tmp_lst.append(decomposed)\n",
    "\n",
    "            tmp_lst.sort()\n",
    "            decomposed_uniques[unique_header] = tmp_lst\n",
    "    else:\n",
    "        raise TypeError('header should be a string representing a column header')\n",
    "\n",
    "    return pd.DataFrame.from_dict(decomposed_uniques)\n",
    "\n",
    "\n",
    "def get_onehot_encoders(table, cols):\n",
    "    encoder_dict = {}\n",
    "    for col in cols:\n",
    "        uniques_vals = get_decomposed_uniques(table, header=col)\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        enc.fit_transform(uniques_vals)\n",
    "        encoder_dict[col] = enc\n",
    "    return encoder_dict\n",
    "\n",
    "\n",
    "def onehot_encode(table, header):\n",
    "    # Create onehot codes for the specidfied column\n",
    "    lst = []\n",
    "    encoder_dict = get_onehot_encoders(table, [header])\n",
    "\n",
    "    count = 0\n",
    "    for index in range(table.shape[0]):\n",
    "        _tmp = np.zeros([1, len(encoder_dict[header].categories_[0])], dtype=int)\n",
    "        if type(table.loc[index, header]) is str:\n",
    "            for decomposed in re.split(custom_sep, table.loc[index, header]):\n",
    "                _tmp |= np.int_(encoder_dict[header].transform([[decomposed]]).toarray())\n",
    "            lst.append(_tmp)\n",
    "\n",
    "        # Update loading bar\n",
    "        if count == 1000:\n",
    "            progress(index, table.shape[0])\n",
    "            count = 0\n",
    "        count += 1\n",
    "\n",
    "    print(\" -> Done\", flush=True)\n",
    "\n",
    "    # Replace dataframe column by encoded values\n",
    "    table.loc[:, header] = pd.Series(lst)\n",
    "\n",
    "    # return the encoder associated to that particular header\n",
    "    return encoder_dict[header]\n",
    "\n",
    "\n",
    "def time_methode(methode, status='', **kwargs):\n",
    "    print('Timing {}'.format(methode.__name__))\n",
    "    if status != '':\n",
    "        print(status)\n",
    "    start_time = datetime.now()\n",
    "    print('Start time: {}'.format(start_time))\n",
    "    ret = methode(**kwargs)\n",
    "    end_time = datetime.now()\n",
    "    print('End time: {}'.format(end_time))\n",
    "    print('{} took: {}'.format(methode.__name__, (end_time - start_time)))\n",
    "    if ret != '':\n",
    "        return ret\n",
    "    else:\n",
    "        ret = 0\n",
    "    return ret\n",
    "\n",
    "\n",
    "def progress(count, total, status=''):\n",
    "    bar_len = 50\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "    _str = ''\n",
    "    percents = np.ceil(100.0 * count / float(total))\n",
    "    bar = '=' * filled_len + ':' * (bar_len - filled_len)\n",
    "\n",
    "    if status == '':\n",
    "        _str = '|{}| {}%'.format(bar, percents)\n",
    "    else:\n",
    "        _str = '|{}| {}% - {}'.format(bar, percents, status)\n",
    "\n",
    "    print('\\r', end='', flush=True)\n",
    "    print(_str, end='', flush=True)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Load data:\n",
    "    Will look for existing files to deserialize prior encoding data. If the files are not found\n",
    "    it will proceed with the original data through encoding.\n",
    "\"\"\"\n",
    "product_encode_file_exist = os.path.isfile(encoded_product_file)\n",
    "package_encode_file_exist = os.path.isfile(encoded_package_file)\n",
    "\n",
    "enc_dic = {}\n",
    "\n",
    "original_product_data = pd.read_csv(product_file, sep=';', encoding='latin1')\n",
    "original_package_data = pd.read_csv(package_file, sep=';', encoding='latin1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "if product_encode_file_exist:\n",
    "    print('Loading encoded product data from existing file...')\n",
    "    product = pd.read_csv(encoded_product_file, sep=separ, encoding=target_encoding)\n",
    "    # Populate onehot encoders dictionnary\n",
    "    for header in product_headers_to_encode:\n",
    "        enc_dic[header] = pickle.load(open(encoder_dir + '{}_data_encoder.pkl'.format(header), 'rb'))\n",
    "else:\n",
    "    product = original_product_data\n",
    "\n",
    "if package_encode_file_exist:\n",
    "    print('Loading encoded package data from existing file...')\n",
    "    package = pd.read_csv(encoded_package_file, sep=separ, encoding=target_encoding)\n",
    "\n",
    "    # Populate onehot encoders dictionnary\n",
    "    for header in package_headers_to_encode:\n",
    "        enc_dic[header] = pickle.load(open(encoder_dir + '{}_data_encoder.pkl'.format(header), 'rb'))\n",
    "else:\n",
    "    package = original_package_data\n",
    "\n",
    "# Make everything lower characters in both tables\n",
    "df_to_lower(product)\n",
    "df_to_lower(package)\n",
    "\n",
    "if product_encode_file_exist:\n",
    "    print('Get unique values for ROUTENAME column of PRODUCT table')\n",
    "    product_unique_values = get_decomposed_uniques(original_product_data, 'ROUTENAME')\n",
    "    print(product_unique_values)\n",
    "    print(enc_dic['ROUTENAME'].categories_[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Auscultation\n",
    "Nous avons déjà prétraitées les données (passage en minuscules des données textuelles) afin de minimiser l'inconsistance\n",
    "entre les valeurs.\n",
    "\n",
    "## Etude des données du fichier 'package'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Assessing completeness of packaging data table')\n",
    "assert_table_completeness(package)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La colonne PRODUCTID ne présente pas de valeurs manquantes. Celle-ci fournit les valeurs concaténées de \n",
    "code produit NDC et de l'identifiant SPL. Cependant, la colonne PRODUCTNDC présente quant à elle 1500 valeurs manquantes\n",
    ". On remarque également des valeurs aberrantes dans ses valeurs.\n",
    "\n",
    "Les valeurs manquantes des colonnes STARTMARKETINGDATE et ENDMARKETINGDATE sont plus nombreuses mais semblent être non \n",
    "bloquantes. Ces deux dernières colonnes sont de type date.\n",
    "\n",
    "La colonne PACKAGEDESCRIPTION est présentée sous forme de phrase et contient de multiples informations: le type de \n",
    "volume, sa valeur et son unité. S'il existe plusieurs contenants pour un objet, ils sont concaténés par un séparateur \n",
    "'>' de manière hiérarchique.\n",
    "\n",
    "Les colonnes NDC_EXCLUDE_FLAG et SAMPLE_PACKAGE, présentant peu de valeurs différentes, et ont l'air facilement \n",
    "traitables numériquement.\n",
    "\"\"\"\n",
    "# %%\n",
    "\"\"\"\n",
    "## Etude des données du fichier 'product'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Assessing completeness product data table')\n",
    "assert_table_completeness(product)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On remarque que la colonne PRODUCTID présente 1560 valeurs manquantes. La colonne PRODUCTNDC quant à elle présente \n",
    "certaines valeurs aberrantes.\n",
    "\"\"\"\n",
    "# %%\n",
    "print(product['PRODUCTNDC'][159:161])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dans la colonne PRODUCTTYPENAME, on remarque 7 valeurs possibles textuelles catégorielles dans cette colonne et aucune\n",
    "valeur manquante. Cette colonne sera donc facilement numérisable. \n",
    "\n",
    "La colonne PROPRIETARYNAME dispose d'un grand nombre de valeurs différentes, de type textuelle. Ces valeurs sont assez \n",
    "variables (phrase, simple mot) décrivant plus ou moins le produit. \n",
    "La colonne PROPRIETARYNAMESUFFIX est du même type que PROPRIETARYNAME, cependant elle présente beaucoup de valeurs \n",
    "nulles, et apporte des informations variantes aux objets. La documentation précise ne pas reconnaître de standard.\n",
    "\n",
    "La colonne NONPROPRIETARYNAME présente seulement 4 valeurs manquantes mais un nombre très important de valeurs \n",
    "textuelles différentes. Elle indique les ingrédients actifs du produit, donc présente ses valeurs sous forme de liste\n",
    "(inconsistante dans sa représentation). Les valeurs manquantes paraissent difficilement remplissables.\n",
    "\n",
    "La colonne DOSAGEFORMNAME présente des données du standard FDA. En les étudiant, on se rend compte que nous pourrions \n",
    "simplifier notre utilisation du standard. En effet, celui-ci apporte une information principale sur le mode \n",
    "d'administration et présente certaines caractéristiques plus spécifique au mode. Ces dernières pourraient être omises \n",
    "pour notre utilisation car trop spécifiques et pouvant être globalisés en gardant seulement l'information principale\n",
    "du mode d'administration.\n",
    "\n",
    "La colonne ROUTENAME présente des données du standard FDA. Chaque objet a la possibilité d'en contenir plusieurs. On \n",
    "remarque que la représentation de données multiples est consistante, via un séparateur ';'. Il y a un nombre conséquent\n",
    "de données manquantes qui seront à priori difficiles à compléter.\n",
    "\n",
    "Les colonnes STARTMARKETINGDATE et ENDMARKETINGDATE sont similaires à celle présentes dans la table 'package'. \n",
    "Cependant, dans cette table, il n'y a aucune valeur manquante pour la colonne STARTMARKETINGDATE.\n",
    "nt de type date, il y a un grand nombre de valeurs manquantes. \n",
    "\n",
    "La colonne MARKETINGCATEGORYNAME présente des données du standard FDA. Il n'y a pas de valeur manquante et seulement \n",
    "10 catégories différentes, la colonne sera donc numérisables facilement. \n",
    "\n",
    "La colonne APPLICATIONNUMBER spécifie pour chaque objet le numéro de catégorie marketing associée (présente dans la \n",
    "colonne MARKETINGCATEGORYNAME). Il y a un nombre important de valeurs manquantes. \n",
    "\n",
    "La colonne LABELERNAME présente des données textuelles très inconsistantes réflétant donc le nombre important de valeurs\n",
    "différentes. Cette colonne parait difficilement numérisables et les valeurs manquantes (557) non complétables. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(product['LABELERNAME'][7252:7255])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La colonne SUBSTANCENAME présente des données du standard FDA, celui-ci est composé de 108 227 catégories différentes.\n",
    "Chaque objet peut présenter plusieurs catégories, la représentation de valeurs multiples est consistante via le \n",
    "séparateur ';'. Cela pourrait expliquer le nombre important de valeurs différentes. Le nombre de valeurs manquantes\n",
    "est important et les valeurs seront difficilement complétables.\n",
    "\n",
    "Les colonnes ACTIVE_NUMERATOR_STRENGTH et ACTIVE_INGRED_UNIT présentent des valeurs liées. Il existe des valeurs\n",
    "multiples et une consistance dans leur représentation via le séparateur ';'. Le nombre de valeurs manquantes est égale \n",
    "pour les deux colonnes. Elles paraissent assez facilement numérisables mais difficilement complétables.\n",
    "\n",
    "La colonne PHARM_CLASSES présente des données du standard FDA, cependant il y en a un extrêmement important. Chaque \n",
    "objet peut disposer de plusieurs valeurs, la représentation de multiples valeurs semblent être consistante via le \n",
    "séparateur ','. \n",
    "Comme précisé par la FDA, ces données sont les catégories pharmaceutiques correspondants aux substances\n",
    "du produit (valeurs contenues dans la colonne SUBSTANCENAME). On sait cependant qu'il existe un nombre assez important \n",
    "de valeurs de noms de substances manquantes. \n",
    "\n",
    "La colonne DEASCHEDULE présente des données du standard FDA. Ces données semblent être facilement numérisables, il y\n",
    "cependant un nombre important de données manquantes qui seront difficilement complétables car nécessite de les traiter\n",
    "un à un par un expert.\n",
    "\n",
    "La colonne NDC_EXCLUDE_FLAG présente seulement la catégorie N pour notre jeu de données, comme précisé dans la \n",
    "documentation. Il n'y a pas de valeur manquante."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(product['NDC_EXCLUDE_FLAG'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Relations entre attributs\n",
    "## Informations communes\n",
    "Les colonnes 'PRODUCTID' des tables 'package' et 'product' contiennent deux informations concaténées: l'id du produit \n",
    "ainsi que le contenu de leur colonne 'PRODUCTNDC', le code label et le code segment produit.  \n",
    "Dans la documentation NDC, il est précisé que c'est pour prévenir le duplicata de lignes.\n",
    "\n",
    "La colonne 'NDCPACKAGECODE' de la table 'package' contient deux informations concaténées: le code segment du package et \n",
    "le contenu de la colonne 'PRODUCTNDC', le code label et le code segment produit.\n",
    "\n",
    "La colonne 'PACKAGEDESCRIPTION' de la table 'package' contient plusieurs informations concaténées. En plus des \n",
    "informations propres à la description du package, il y a dans la majorité des objets la valeur 'NDCPACKAGECODE' associée\n",
    ".\n",
    "\n",
    "La colonne 'APPLICATIONNUMBER' de la table 'product' présente la majorité du temps le contenu de la colonne \n",
    "'MARKETINGCATEGORYNAME' et spécifie son numéro de série.\n",
    "\n",
    "Dans les deux tables, il existe des colonnes 'STARTMARKETINGDATE',  'ENDMARKETINGDATE' et 'NDCEXLUDEDFLAG'. \n",
    "Elles semblent présenter les mêmes informations.\n",
    "\n",
    "## Corrélation\n",
    "Pour la table 'product':\n",
    "Il semble pouvoir exister une corrélation entre les attributs 'ROUTENAME' et 'DOSAGEFORMNAME' qui présentent des idées \n",
    "d'administration similaires. \n",
    "On peut également considérer l'existance d'une corrélation entre les modes d'administration\n",
    "et les dosages du médicament, donc les attributs 'ROUTENAME', 'DOSAGEFORMNAME' et ceux 'ACTIVE_NUMERATOR_STRENGTH', \n",
    "'ACTIVE_INGRED_UNIT'.\n",
    "L'attribut 'PHARM_CLASS' semble pouvoir être corrélé à l'attribut 'SUBSTANCENAME'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Correction des incohérences\n",
    "## Table 'product'\n",
    "Il y a de nombreux points à vérifier pour la table 'product'. \n",
    "Tout d'abord, on peut s'intéresser aux colonnes date STARTMARKETINGDATE, ENDMARKETINGDATE et \n",
    "LISTING_RECORD_CERTIFIED_THROUGH. \n",
    "On se rend compte de l'existence de données aberrantes que l'on décide d'ignorer et de supprimer leur valeur."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# conversion to datetime format\n",
    "# TODO: fix AttributeError: 'NoneType' object has no attribute '__name__'\n",
    "def date_convert(dc):\n",
    "    for c in dc:\n",
    "        product[c] = pd.to_datetime(product[c], errors='coerce', format='%Y%m%d')\n",
    "\n",
    "\n",
    "date_cols = ['STARTMARKETINGDATE', 'ENDMARKETINGDATE', 'LISTING_RECORD_CERTIFIED_THROUGH']\n",
    "if not product_encode_file_exist:\n",
    "    time_methode(date_convert, **dict(dc=date_cols))\n",
    "# %%\n",
    "\"\"\"\n",
    "Aussi, il existerait une incohérence si la date de fin de mise sur le marché est moins récente que la date de début de \n",
    "mise sur le marché.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compare STARTMARKETINGDATE and ENDMARKETINGDATE\n",
    "nb = product[product['STARTMARKETINGDATE'] > product['ENDMARKETINGDATE']].shape[0]\n",
    "print(f\"Nombre d'incohérences entre STARTMARKETINGDATE et ENDMARKETINGDATE: {nb}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La colonne LISTING_RECORD_CERTIFIED_THROUGH permet de savoir si la certification du produit est expiré. On considère \n",
    "donc que le produit n'est plus à jour (et donc à supprimer de notre dataset) si la date précisée dans cette \n",
    "colonne est passée. \n",
    "\"\"\"\n",
    "# %%\n",
    "\n",
    "product = product.drop(product[product['LISTING_RECORD_CERTIFIED_THROUGH'] < datetime.now()].index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La colonne NDC_EXCLUDE_FLAG ne devrait présenter que des valeurs de la catégorie 'N' pour notre dataset, comme le \n",
    "précise la documentation FDA. On le vérifie simplement:\n",
    "\"\"\"\n",
    "# %%\n",
    "\n",
    "print(product['NDC_EXCLUDE_FLAG'].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Les colonnes ACTIVE_NUMERATOR_STRENGTH et ACTIVE_INGRED_UNIT présentent des valeurs multiples liées. Leur nombre dans\n",
    "chacune des colonnes doit donc être égal. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "comp = product['ACTIVE_NUMERATOR_STRENGTH'].str.count(';').fillna(0) == \\\n",
    "       product['ACTIVE_INGRED_UNIT'].str.count(';').fillna(0)\n",
    "nb = len(product[np.logical_not(comp)][['ACTIVE_NUMERATOR_STRENGTH', 'ACTIVE_INGRED_UNIT']])\n",
    "print(f'Nombre d\\'incohérences entre ACTIVE_NUMERATOR_STRENGTH et ACTIVE_INGRED_UNIT: {nb}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La colonne PRODUCTNDC présente certaines valeurs aberrantes que nous décidons de récupérer de la première\n",
    "partie de la valeur du PRODUCTID associée. En effet, celui-ci étant un duplicata, celui-ci peut être considéré comme \n",
    "correct."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def replace_outliers_productndc(table):\n",
    "    outliers = table['PRODUCTNDC'][~table['PRODUCTNDC'].str.contains(r'\\d{4,5}-\\d{3,4}', regex=True, na=False)]\n",
    "    id_outliers = table.iloc[outliers.index.values.tolist()]['PRODUCTID']\n",
    "    for (io, i) in zip(id_outliers, outliers.index.values.tolist()):\n",
    "        table.at[i, 'PRODUCTNDC'] = re.match('(^[^_]+)', io).group(0)\n",
    "\n",
    "\n",
    "replace_outliers_productndc(product)\n",
    "# %%\n",
    "\"\"\"\n",
    "Certaines colonnes représentent des standards FDA, afin d'assurer aucune incohérence dans leurs valeurs, \n",
    "nous décidons de vérifier que leurs valeurs sont incluses dans les standards fournis par la FDA (disponible \n",
    "https://www.fda.gov/industry/fda-resources-data-standards/structured-product-labeling-resources). \n",
    "On s'intéressera donc aux colonnes: DOSAGEFORMNAME, ROUTENAME, MARKETINGCATEGORYNAME, DEASCHEDULE, NDC_EXCLUDE_FLAG \n",
    "Les colonnes SUBSTANCENAME et PHARM_CLASSES représentent également des standards FDA, cependant, le nombre de valeurs\n",
    "possibles fournis par la FDA est extrêment important. Nous décidons, par mesure de possibilité, ne pas les traiter.\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def check_categories(table, column_name, standard):\n",
    "    categories = pd.Series(table[column_name].unique()).dropna()\n",
    "    lowercase_standard = map(str.lower, pd.Series(standard))\n",
    "    return categories.isin(lowercase_standard).any().any()\n",
    "\n",
    "\n",
    "def check_dict_categories(table, column_name, standard):\n",
    "    categories = pd.Series(table[column_name].unique()).dropna()\n",
    "    lowercase_standard = dict((k.lower(), v.lower()) for k, v in standard.items())\n",
    "    return categories.isin(list(lowercase_standard.values())).any().any()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = ['DEASCHEDULE', 'NDC_EXCLUDE_FLAG', 'ROUTENAME', 'MARKETINGCATEGORYNAME']\n",
    "standards = [standard_deaschedule, standard_ndcexcludeflag, standard_routename, standard_marketingcategoryname]\n",
    "for (col_name, stand) in zip(cols, standards):\n",
    "    check = check_categories(product, col_name, stand)\n",
    "    print(f'Toutes les valeurs de la colonne {col_name} correspondent au stardard FDA: {check}')\n",
    "\n",
    "check = check_dict_categories(product, 'DOSAGEFORMNAME', standard_dosageformname)\n",
    "print(f'Toutes les valeurs de la colonne DOSAGEFORMNAME correspondent au stardard FDA: {check}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def check_format_standard(table, cols, reg):\n",
    "    for (c, r) in zip(cols, reg):\n",
    "        check = table[c].str.contains(r, regex=True, na=False).any().any()\n",
    "        print(f'La colonne {c} répond à la standardisation: {check}')\n",
    "\n",
    "\n",
    "check_format_standard(product, ['PRODUCTNDC', 'PRODUCTID'], [r'\\d{4,5}-\\d{3,4}', r'\\d{4,5}-\\d{3,4}_[A-Za-z0-9\\-]+'])\n",
    "# %%\n",
    "\"\"\"\n",
    "## Table 'package'\n",
    "\n",
    "Traitement des colonnes STARTMARKETINGDATE et ENDMARKETINGDATE similairement à la table 'product'.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "date_cols = ['STARTMARKETINGDATE', 'ENDMARKETINGDATE']\n",
    "if not package_encode_file_exist:\n",
    "    time_methode(date_convert, **dict(dc=date_cols))\n",
    "\n",
    "# compare STARTMARKETINGDATE and ENDMARKETINGDATE\n",
    "nb = product[product['STARTMARKETINGDATE'] > product['ENDMARKETINGDATE']].shape[0]\n",
    "print(f\"Nombre d'incohérences entre STARTMARKETINGDATE et ENDMARKETINGDATE: {nb}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La colonne NDC_EXCLUDE_FLAG représente un stardard FDA que l'on vérifie comme pour la table 'product'.\n",
    "\"\"\"\n",
    "# %%\n",
    "cols = ['NDC_EXCLUDE_FLAG']\n",
    "standards = [standard_ndcexcludeflag]\n",
    "for (col_name, stand) in zip(cols, standards):\n",
    "    check = check_categories(product, col_name, stand)\n",
    "    print(f'Toutes les valeurs de la colonne {col_name} correspondent au stardard FDA: {check}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La colonne PRODUCTNDC présente également des données aberrantes du même type que l'on avait trouvé dans la table product\n",
    "."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "replace_outliers_productndc(package)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Les colonnes PRODUCTID, PRODUCTNDC et NDCPACKAGECODE suivent un format spécifié :\n",
    "- PRODUCTNDC doit répondre à une structure de digits telle que {3-5}, {3-4}, {4-4}, {4-5}.\n",
    "- PRODUCTID concatène la valeur du PRODUCTNDC et un identifiant SPL séparé par un '_'.\n",
    "- NDCPACKAGECODE concatène la valeur du PRODUCTNDC et un code segment de 2 digits séparé par '-'.\n",
    "\n",
    "\"\"\"\n",
    "# %%\n",
    "cols = ['PRODUCTNDC', 'PRODUCTID', 'NDCPACKAGECODE']\n",
    "reg = [r'\\d{4,5}-\\d{3,4}', r'\\d{4,5}-\\d{3,4}_[A-Za-z0-9\\-]+', r'\\d{4,5}-\\d{3,4}-\\d{2}']\n",
    "check_format_standard(package, cols, reg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Données manquantes\n",
    "## Table 'package'\n",
    "On s'intéresse aux données manquantes dans les colonnes PRODUCTNDC et NDCPACKAGECODE."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not package_encode_file_exist:\n",
    "    package_missing_ndcpackagecode = package.iloc[np.where(pd.isnull(package['NDCPACKAGECODE']))]\n",
    "    values = package_missing_ndcpackagecode['PACKAGEDESCRIPTION'].str.extract(r'\\((.*?)\\).*')\n",
    "    for index, row in values.iterrows():\n",
    "        package.loc[index, 'NDCPACKAGECODE'] = row[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not package_encode_file_exist:\n",
    "    package_missing_productndc = package.iloc[np.where(pd.isnull(package['PRODUCTNDC']))]\n",
    "    values = package_missing_productndc['NDCPACKAGECODE'].str.extract(r'^([\\w]+-[\\w]+)')\n",
    "    for index, row in values.iterrows():\n",
    "        package.loc[index, 'PRODUCTNDC'] = row[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "if not package_encode_file_exist:\n",
    "    # TODO : find a way to retrieve PRODUCTID from 'product' table\n",
    "    package_missing_ndcproductid = package.iloc[np.where(pd.isnull(package['PRODUCTID']))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il existe des valeurs manquantes pour les colonnes 'STARTMARKETINGDATE' et 'ENDMARKETINGDATE' dans la table 'package'\n",
    "mais on choisit de ne pas les compléter car on ne peut effectuer d'estimation précise. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Table 'product'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Duplications données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformation en données numériques (après question 8)\n",
    "## Table 'package'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Table 'product'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# TODO: hash PROPRIETARYNAME NONPROPRIETARYNAME LABELERNAME PROPRIETARYNAMESUFFIX\n",
    "# TODO: separate and hash SUBSTANCENAME PHARM_CLASSES\n",
    "# TODO : split ACTIVE_INGRED_UNIT by '/' (nan others), then one hot each col\n",
    "\n",
    "# TODO: ideas?? APPLICATIONNUMBER\n",
    "# %%\n",
    "# TODO : analysis ratio per category"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encodage onehot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Call and time onehot encoding for all predefined columns\n",
    "if not os.path.isdir(encoder_dir):\n",
    "    os.mkdir(encoder_dir)\n",
    "if not product_encode_file_exist:\n",
    "    for header in product_headers_to_encode:\n",
    "        enc_dic[header] = time_methode(onehot_encode, header, **(dict(table=product, header=header)))\n",
    "        pickle.dump(enc_dic[header], open(encoder_dir + '{}_data_encoder.pkl'.format(header), 'wb'),\n",
    "                    pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "if not package_encode_file_exist:\n",
    "    for header in package_headers_to_encode:\n",
    "        enc_dic[header] = time_methode(onehot_encode, header, **(dict(table=package, header=header)))\n",
    "        pickle.dump(enc_dic[header], open(encoder_dir + '{}_data_encoder.pkl'.format(header), 'wb'),\n",
    "                    pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "if not os.path.isdir(encoding_dir):\n",
    "    os.mkdir(encoding_dir)\n",
    "# Prints out encding of each category for a given column in a txt file\n",
    "for header, enc in enc_dic.items():\n",
    "    file = open(encoding_dir + 'Encoding_{}.txt'.format(header), 'w')\n",
    "    for category in enc.categories_[0]:\n",
    "        tmp_str = str(enc.transform([[category]]).toarray())\n",
    "        tmp_str = category + ' ' * (40 - len(category)) + tmp_str.replace('\\n', '\\n' + ' ' * 40) + '\\n'\n",
    "        file.write(tmp_str)\n",
    "    file.close()\n",
    "\n",
    "# Save transformed data to file\n",
    "if not product_encode_file_exist:\n",
    "    time_methode(product.to_csv, **(dict(path_or_buf=encoded_product_file,\n",
    "                                         index=False,\n",
    "                                         sep=separ,\n",
    "                                         encoding=target_encoding,\n",
    "                                         quoting=csv.QUOTE_NONNUMERIC)))\n",
    "\n",
    "if not product_encode_file_exist:\n",
    "    time_methode(package.to_csv, **(dict(path_or_buf=encoded_package_file,\n",
    "                                         index=False,\n",
    "                                         sep=separ,\n",
    "                                         encoding=target_encoding,\n",
    "                                         quoting=csv.QUOTE_NONNUMERIC)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Résultats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Encoded product data:')\n",
    "print(product)\n",
    "product"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Encoded packaging data:')\n",
    "print(package)\n",
    "package\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}