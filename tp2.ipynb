{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from _datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "product_headers_to_encode = ['ROUTENAME', 'DOSAGEFORMNAME', 'SUBSTANCENAME', 'MARKETINGCATEGORYNAME', 'PHARM_CLASSES']\n",
    "\n",
    "date_cols = ['STARTMARKETINGDATE', 'ENDMARKETINGDATE', 'LISTING_RECORD_CERTIFIED_THROUGH']\n",
    "\n",
    "standard_dosageformname = {\"AEROSOL\": \"AEROSOL\", \"AEROSOL, FOAM\": \"AEROSOL\", \"AEROSOL, METERED\": \"AEROSOL\",\n",
    "                           \"AEROSOL, POWDER\": \"AEROSOL\", \"AEROSOL, SPRAY\": \"AEROSOL\", \"BAR\": \"BAR\",\n",
    "                           \"BAR, CHEWABLE\": \"BAR\", \"BEAD\": \"BEAD\", \"CAPSULE\": \"CAPSULE\", \"CAPSULE, COATED\": \"CAPSULE\",\n",
    "                           \"CAPSULE, COATED PELLETS\": \"CAPSULE\", \"CAPSULE, COATED, EXTENDED RELEASE\": \"CAPSULE\",\n",
    "                           \"CAPSULE, DELAYED RELEASE\": \"CAPSULE\", \"CAPSULE, DELAYED RELEASE PELLETS\": \"CAPSULE\",\n",
    "                           \"CAPSULE, EXTENDED RELEASE\": \"CAPSULE\", \"CAPSULE, FILM COATED, EXTENDED RELEASE\": \"CAPSULE\",\n",
    "                           \"CAPSULE, GELATIN COATED\": \"CAPSULE\", \"CAPSULE, LIQUID FILLED\": \"CAPSULE\",\n",
    "                           \"CELLULAR SHEET\": \"CELLULAR SHEET\", \"CHEWABLE GEL\": \"CHEWABLE GEL\", \"CLOTH\": \"CLOTH\",\n",
    "                           \"CONCENTRATE\": \"CONCENTRATE\", \"CREAM\": \"CREAM\", \"CREAM, AUGMENTED\": \"CREAM\",\n",
    "                           \"CRYSTAL\": \"CRYSTAL\", \"DISC\": \"DISC\", \"DOUCHE\": \"DOUCHE\", \"DRESSING\": \"DRESSING\",\n",
    "                           \"ELIXIR\": \"ELIXIR\", \"EMULSION\": \"EMULSION\", \"ENEMA\": \"ENEMA\", \"EXTRACT\": \"EXTRACT\",\n",
    "                           \"FIBER, EXTENDED RELEASE\": \"FIBER\", \"FILM\": \"FILM\", \"FILM, EXTENDED RELEASE\": \"FILM\",\n",
    "                           \"FILM, SOLUBLE\": \"FILM\", \"FOR SOLUTION\": \"FOR SOLUTION\", \"FOR SUSPENSION\": \"FOR SUSPENSION\",\n",
    "                           \"FOR SUSPENSION, EXTENDED RELEASE\": \"FOR SUSPENSION\", \"GAS\": \"GAS\", \"GEL\": \"GEL\",\n",
    "                           \"GEL, DENTIFRICE\": \"GEL\", \"GEL, METERED\": \"GEL\", \"GLOBULE\": \"GLOBULE\", \"GRANULE\": \"GRANULE\",\n",
    "                           \"GRANULE, DELAYED RELEASE\": \"GRANULE\", \"GRANULE, EFFERVESCENT\": \"GRANULE\",\n",
    "                           \"GRANULE, FOR SOLUTION\": \"GRANULE\", \"GRANULE, FOR SUSPENSION\": \"GRANULE\",\n",
    "                           \"GRANULE, FOR SUSPENSION, EXTENDED RELEASE\": \"GRANULE\", \"GUM\": \"GUM\", \"GUM, CHEWING\": \"GUM\",\n",
    "                           \"IMPLANT\": \"IMPLANT\", \"INHALANT\": \"INHALANT\", \"INJECTABLE FOAM\": \"INJECTABLE FOAM\",\n",
    "                           \"INJECTABLE\": \"INJECTABLE\", \"INJECTABLE, LIPOSOMAL\": \"INJECTABLE\", \"INJECTION\": \"INJECTION\",\n",
    "                           \"INJECTION, EMULSION\": \"INJECTION\", \"INJECTION, LIPID COMPLEX\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, FOR SOLUTION\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, FOR SUSPENSION\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, FOR SUSPENSION, EXTENDED RELEASE\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, LYOPHILIZED, FOR LIPOSOMAL SUSPENSION\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, LYOPHILIZED, FOR SOLUTION\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, LYOPHILIZED, FOR SUSPENSION\": \"INJECTION\",\n",
    "                           \"INJECTION, POWDER, LYOPHILIZED, FOR SUSPENSION, EXTENDED RELEASE\": \"INJECTION\",\n",
    "                           \"INJECTION, SOLUTION\": \"INJECTION\", \"INJECTION, SOLUTION, CONCENTRATE\": \"INJECTION\",\n",
    "                           \"INJECTION, SUSPENSION\": \"INJECTION\", \"INJECTION, SUSPENSION, EXTENDED RELEASE\": \"INJECTION\",\n",
    "                           \"INJECTION, SUSPENSION, LIPOSOMAL\": \"INJECTION\",\n",
    "                           \"INJECTION, SUSPENSION, SONICATED\": \"INJECTION\", \"INSERT\": \"INSERT\",\n",
    "                           \"INSERT, EXTENDED RELEASE\": \"INSERT\", \"INTRAUTERINE DEVICE\": \"INTRAUTERINE DEVICE\",\n",
    "                           \"IRRIGANT\": \"IRRIGANT\", \"JELLY\": \"JELLY\", \"KIT\": \"KIT\", \"LINIMENT\": \"LINIMENT\",\n",
    "                           \"LIPSTICK\": \"LIPSTICK\", \"LIQUID\": \"LIQUID\", \"LIQUID, EXTENDED RELEASE\": \"LIQUID\",\n",
    "                           \"LOTION\": \"LOTION\", \"LOTION, AUGMENTED\": \"LOTION\", \"LOTION/SHAMPOO\": \"LOTION/SHAMPOO\",\n",
    "                           \"LOZENGE\": \"LOZENGE\", \"MOUTHWASH\": \"MOUTHWASH\", \"NOT APPLICABLE\": \"NOT APPLICABLE\",\n",
    "                           \"OIL\": \"OIL\", \"OINTMENT\": \"OINTMENT\", \"OINTMENT, AUGMENTED\": \"OINTMENT\", \"PASTE\": \"PASTE\",\n",
    "                           \"PASTE, DENTIFRICE\": \"PASTE\", \"PASTILLE\": \"PASTILLE\", \"PATCH\": \"PATCH\",\n",
    "                           \"PATCH, EXTENDED RELEASE\": \"PATCH\",\n",
    "                           \"PATCH, EXTENDED RELEASE, ELECTRICALLY CONTROLLED\": \"PATCH\", \"PELLET\": \"PELLET\",\n",
    "                           \"PELLET, IMPLANTABLE\": \"PELLET\", \"PELLETS, COATED, EXTENDED RELEASE\": \"PELLETS\",\n",
    "                           \"PILL\": \"PILL\", \"PLASTER\": \"PLASTER\", \"POULTICE\": \"POULTICE\", \"POWDER\": \"POWDER\",\n",
    "                           \"POWDER, DENTIFRICE\": \"POWDER\", \"POWDER, FOR SOLUTION\": \"POWDER\",\n",
    "                           \"POWDER, FOR SUSPENSION\": \"POWDER\", \"POWDER, METERED\": \"POWDER\", \"RING\": \"RING\",\n",
    "                           \"RINSE\": \"RINSE\", \"SALVE\": \"SALVE\", \"SHAMPOO\": \"SHAMPOO\", \"SHAMPOO, SUSPENSION\": \"SHAMPOO\",\n",
    "                           \"SOAP\": \"SOAP\", \"SOLUTION\": \"SOLUTION\", \"SOLUTION, CONCENTRATE\": \"SOLUTION\",\n",
    "                           \"SOLUTION, FOR SLUSH\": \"SOLUTION\", \"SOLUTION, GEL FORMING / DROPS\": \"SOLUTION\",\n",
    "                           \"SOLUTION, GEL FORMING, EXTENDED RELEASE\": \"SOLUTION\", \"SOLUTION/ DROPS\": \"SOLUTION\",\n",
    "                           \"SPONGE\": \"SPONGE\", \"SPRAY\": \"SPRAY\", \"SPRAY, METERED\": \"SPRAY\",\n",
    "                           \"SPRAY, SUSPENSION\": \"SPRAY\", \"STICK\": \"STICK\", \"STRIP\": \"STRIP\",\n",
    "                           \"SUPPOSITORY\": \"SUPPOSITORY\", \"SUPPOSITORY, EXTENDED RELEASE\": \"SUPPOSITORY\",\n",
    "                           \"SUSPENSION\": \"SUSPENSION\", \"SUSPENSION, EXTENDED RELEASE\": \"SUSPENSION\",\n",
    "                           \"SUSPENSION/ DROPS\": \"SUSPENSION\", \"SWAB\": \"SWAB\", \"SYRUP\": \"SYRUP\",\n",
    "                           \"SYSTEM\": \"SYSTEM\", \"TABLET\": \"TABLET\", \"TABLET, CHEWABLE\": \"TABLET\",\n",
    "                           \"TABLET, CHEWABLE, EXTENDED RELEASE\": \"TABLET\", \"TABLET, COATED\": \"TABLET\",\n",
    "                           \"TABLET, COATED PARTICLES\": \"TABLET\", \"TABLET, DELAYED RELEASE\": \"TABLET\",\n",
    "                           \"TABLET, DELAYED RELEASE PARTICLES\": \"TABLET\", \"TABLET, EFFERVESCENT\": \"TABLET\",\n",
    "                           \"TABLET, EXTENDED RELEASE\": \"TABLET\", \"TABLET, FILM COATED\": \"TABLET\",\n",
    "                           \"TABLET, FILM COATED, EXTENDED RELEASE\": \"TABLET\", \"TABLET, FOR SOLUTION\": \"TABLET\",\n",
    "                           \"TABLET, FOR SUSPENSION\": \"TABLET\", \"TABLET, MULTILAYER\": \"TABLET\",\n",
    "                           \"TABLET, MULTILAYER, EXTENDED RELEASE\": \"TABLET\", \"TABLET, ORALLY DISINTEGRATING\": \"TABLET\",\n",
    "                           \"TABLET, ORALLY DISINTEGRATING, DELAYED RELEASE\": \"TABLET\", \"TABLET, SOLUBLE\": \"TABLET\",\n",
    "                           \"TABLET, SUGAR COATED\": \"TABLET\", \"TABLET WITH SENSOR\": \"TABLET\",\n",
    "                           \"TAMPON\": \"TAMPON\", \"TAPE\": \"TAPE\", \"TINCTURE\": \"TINCTURE\", \"TROCHE\": \"TROCHE\",\n",
    "                           \"WAFER\": \"WAFER\"}\n",
    "standard_routename = [\"AURICULAR (OTIC)\", \"BUCCAL\", \"CONJUNCTIVAL\", \"CUTANEOUS\", \"DENTAL\", \"ELECTRO-OSMOSIS\",\n",
    "                      \"ENDOCERVICAL\", \"ENDOSINUSIAL\", \"ENDOTRACHEAL\", \"ENTERAL\", \"EPIDURAL\", \"EXTRA-AMNIOTIC\",\n",
    "                      \"EXTRACORPOREAL\", \"HEMODIALYSIS\", \"INFILTRATION\", \"INTERSTITIAL\", \"INTRA-ABDOMINAL\",\n",
    "                      \"INTRA-AMNIOTIC\", \"INTRA-ARTERIAL\", \"INTRA-ARTICULAR\", \"INTRABILIARY\", \"INTRABRONCHIAL\",\n",
    "                      \"INTRABURSAL\", \"INTRACANALICULAR\", \"INTRACARDIAC\", \"INTRACARTILAGINOUS\", \"INTRACAUDAL\",\n",
    "                      \"INTRACAVERNOUS\", \"INTRACAVITARY\", \"INTRACEREBRAL\", \"INTRACISTERNAL\", \"INTRACORNEAL\",\n",
    "                      \"INTRACORONAL, DENTAL\", \"INTRACORONARY\", \"INTRACORPORUS CAVERNOSUM\", \"INTRACRANIAL\",\n",
    "                      \"INTRADERMAL\", \"INTRADISCAL\", \"INTRADUCTAL\", \"INTRADUODENAL\", \"INTRADURAL\", \"INTRAEPICARDIAL\",\n",
    "                      \"INTRAEPIDERMAL\", \"INTRAESOPHAGEAL\", \"INTRAGASTRIC\", \"INTRAGINGIVAL\", \"INTRAHEPATIC\",\n",
    "                      \"INTRAILEAL\", \"INTRALESIONAL\", \"INTRALINGUAL\", \"INTRALUMINAL\", \"INTRALYMPHATIC\", \"INTRAMAMMARY\",\n",
    "                      \"INTRAMEDULLARY\", \"INTRAMENINGEAL\", \"INTRAMUSCULAR\", \"INTRANODAL\", \"INTRAOCULAR\", \"INTRAOMENTUM\",\n",
    "                      \"INTRAOVARIAN\", \"INTRAPERICARDIAL\", \"INTRAPERITONEAL\", \"INTRAPLEURAL\", \"INTRAPROSTATIC\",\n",
    "                      \"INTRAPULMONARY\", \"INTRARUMINAL\", \"INTRASINAL\", \"INTRASPINAL\", \"INTRASYNOVIAL\", \"INTRATENDINOUS\",\n",
    "                      \"INTRATESTICULAR\", \"INTRATHECAL\", \"INTRATHORACIC\", \"INTRATUBULAR\", \"INTRATUMOR\", \"INTRATYMPANIC\",\n",
    "                      \"INTRAUTERINE\", \"INTRAVASCULAR\", \"INTRAVENOUS\", \"INTRAVENTRICULAR\", \"INTRAVESICAL\",\n",
    "                      \"INTRAVITREAL\", \"IONTOPHORESIS\", \"IRRIGATION\", \"LARYNGEAL\", \"NASAL\", \"NASOGASTRIC\",\n",
    "                      \"NOT APPLICABLE\", \"OCCLUSIVE DRESSING TECHNIQUE\", \"OPHTHALMIC\", \"ORAL\", \"OROPHARYNGEAL\",\n",
    "                      \"PARENTERAL\", \"PERCUTANEOUS\", \"PERIARTICULAR\", \"PERIDURAL\", \"PERINEURAL\", \"PERIODONTAL\", \"RECTAL\",\n",
    "                      \"RESPIRATORY (INHALATION)\", \"RETROBULBAR\", \"SOFT TISSUE\", \"SUBARACHNOID\", \"SUBCONJUNCTIVAL\",\n",
    "                      \"SUBCUTANEOUS\", \"SUBGINGIVAL\", \"SUBLINGUAL\", \"SUBMUCOSAL\", \"SUBRETINAL\", \"TOPICAL\", \"TRANSDERMAL\",\n",
    "                      \"TRANSENDOCARDIAL\", \"TRANSMUCOSAL\", \"TRANSPLACENTAL\", \"TRANSTRACHEAL\", \"TRANSTYMPANIC\",\n",
    "                      \"URETERAL\", \"URETHRAL\", \"VAGINAL\"]\n",
    "standard_marketingcategoryname = [\"ANADA\", \"ANDA\", \"Approved Drug Product Manufactured Under Contract\", \"BLA\",\n",
    "                                  \"Bulk ingredient\", \"Bulk Ingredient For Animal Drug Compounding\",\n",
    "                                  \"Bulk Ingredient For Human Prescription Compounding\", \"Conditional NADA\", \"Cosmetic\",\n",
    "                                  \"Dietary Supplement\", \"Drug for Further Processing\", \"Exempt device\", \"Export only\",\n",
    "                                  \"Humanitarian Device Exemption\", \"IND\", \"Medical Food\",\n",
    "                                  \"Legally Marketed Unapproved New Animal Drugs for Minor Species\", \"NADA\", \"NDA\",\n",
    "                                  \"NDA authorized generic\", \"OTC Monograph Drug Product Manufactured Under Contract\",\n",
    "                                  \"OTC monograph final\", \"OTC monograph not final\", \"Premarket Application\",\n",
    "                                  \"Premarket Notification\", \"Unapproved drug for use in drug shortage\",\n",
    "                                  \"Unapproved drug other\", \"Unapproved Drug Product Manufactured Under Contract\",\n",
    "                                  \"Unapproved homeopathic\", \"Unapproved medical gas\"]\n",
    "standard_deaschedule = [\"CI\", \"CII\", \"CIII\", \"CIV\", \"CV\"]\n",
    "standard_ndcexcludeflag = [\"N\"]\n",
    "\n",
    "target_encoding = 'utf-8'\n",
    "separ = '|'\n",
    "custom_sep = ' ?[|,;:<>] ?|^ | $'\n",
    "\n",
    "product_file = 'Product.csv'\n",
    "package_file = 'Package.csv'\n",
    "\n",
    "encoder_dir = 'encoders/'\n",
    "encoding_dir = 'encoding_dic/'\n",
    "\n",
    "\n",
    "def assert_table_completeness(table):\n",
    "    empty_cells = table.shape[0] - table.count(axis=0)\n",
    "    unique_values = table.nunique(axis=0)\n",
    "\n",
    "    print('Empty cells:\\n{}\\n'.format(empty_cells))\n",
    "    print('Unique values:\\n{}\\n'.format(unique_values))\n",
    "\n",
    "\n",
    "def assert_product_id_completeness(table, header):\n",
    "    empty_cells = table.shape[0] - table.count(axis=0)\n",
    "    unique_values = table.nunique(axis=0)\n",
    "\n",
    "    if empty_cells[header] == 0:\n",
    "        print('No empty values in the {} column'.format(header))\n",
    "    else:\n",
    "        print('There are {} empty values in the {} column'.format(empty_cells[header], header))\n",
    "\n",
    "    if unique_values[header] == table.shape[0]:\n",
    "        print('No duplicat values in the {} column'.format(header))\n",
    "    else:\n",
    "        print(\n",
    "            'There are {} duplicat values in the {} column\\n\\n'.format(table.shape[0] - unique_values[header], header))\n",
    "\n",
    "\n",
    "def get_unique_values(table, headers=''):\n",
    "    uniques = {}\n",
    "    if headers == '':\n",
    "        cols = table.columns.values\n",
    "        for n, c in enumerate(cols):\n",
    "            uniques[c] = pd.unique(table[c])\n",
    "    elif type(headers) is list:\n",
    "        for header in headers:\n",
    "            uniques[header] = pd.unique(table[header])\n",
    "    elif type(headers) is str:\n",
    "        uniques[headers] = pd.unique(table[headers])\n",
    "    return uniques\n",
    "\n",
    "\n",
    "def df_to_lower(table, columns='all'):\n",
    "    cols = table.columns.values if columns == 'all' else columns\n",
    "    for c in cols:\n",
    "        try:\n",
    "            table[c] = table[c].str.lower()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "def get_decomposed_uniques(table, header):\n",
    "    decomposed_uniques = {}\n",
    "    if type(header) is str:\n",
    "        for unique_header, uniques in get_unique_values(table, header).items():\n",
    "            tmp_lst = []\n",
    "            for val in uniques:\n",
    "                if type(val) is str:\n",
    "                    for decomposed in re.split(custom_sep, val):\n",
    "                        if decomposed != '' and not decomposed in tmp_lst:\n",
    "                            tmp_lst.append(decomposed)\n",
    "\n",
    "            tmp_lst.sort()\n",
    "            decomposed_uniques[unique_header] = tmp_lst\n",
    "    else:\n",
    "        raise TypeError('header should be a string representing a column header')\n",
    "\n",
    "    return pd.DataFrame.from_dict(decomposed_uniques)\n",
    "\n",
    "\n",
    "def get_onehot_encoders(table, cols):\n",
    "    encoder_dict = {}\n",
    "    for col in cols:\n",
    "        uniques_vals = get_decomposed_uniques(table, header=col)\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', dtype=int)\n",
    "        enc.fit(uniques_vals)\n",
    "        encoder_dict[col] = enc\n",
    "    return encoder_dict\n",
    "\n",
    "\n",
    "def onehot_encode(table, header):\n",
    "    # Create onehot codes for the specidfied column\n",
    "    lst = []\n",
    "    lst2 = []\n",
    "    encoder_dict = get_onehot_encoders(table, [header])\n",
    "\n",
    "    count, count2 = 0, 0\n",
    "    for index in table.index.values:\n",
    "        count2+=1\n",
    "        # _tmp = np.zeros([1, len(encoder_dict[header].categories_[0])], dtype=int)\n",
    "        lst = []\n",
    "        if type(table.loc[index, header]) is str:\n",
    "            for decomposed in re.split(custom_sep, table.loc[index, header]):\n",
    "                # _tmp |= np.int_(encoder_dict[header].transform([[decomposed]]).toarray())\n",
    "                if not np.int_(encoder_dict[header].transform([[decomposed]]).indices[0]) in lst:\n",
    "                    lst.append(np.int_(encoder_dict[header].transform([[decomposed]]).indices[0]))\n",
    "            lst.sort()\n",
    "            lst2.append(lst)\n",
    "\n",
    "        # Update loading bar\n",
    "        # TODO fix 100000000% caused by sparse indexing after droping NA - not that important\n",
    "        if count == 1000:\n",
    "            progress(count2, table.shape[0])\n",
    "            count = 0\n",
    "        count += 1\n",
    "\n",
    "    print(\" -> Done\", flush=True)\n",
    "\n",
    "    # Replace dataframe column by encoded values\n",
    "    table.loc[:, header] = pd.Series(lst2)\n",
    "\n",
    "    # return the encoder associated to that particular header\n",
    "    return encoder_dict[header]\n",
    "\n",
    "\n",
    "def time_methode(methode, status='', **kwargs):\n",
    "    print('Timing {}'.format(methode.__name__))\n",
    "    if status != '':\n",
    "        print(status)\n",
    "    start_time = datetime.now()\n",
    "    print('Start time: {}'.format(start_time))\n",
    "    ret = methode(**kwargs)\n",
    "    end_time = datetime.now()\n",
    "    print('End time: {}'.format(end_time))\n",
    "    print('{} took: {}'.format(methode.__name__, (end_time - start_time)))\n",
    "    if ret != '':\n",
    "        return ret\n",
    "    else:\n",
    "        ret = 0\n",
    "    return ret\n",
    "\n",
    "\n",
    "def progress(count, total, status=''):\n",
    "    bar_len = 50\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "    _str = ''\n",
    "    percents = np.ceil(100.0 * count / float(total))\n",
    "    bar = '=' * filled_len + ':' * (bar_len - filled_len)\n",
    "\n",
    "    if status == '':\n",
    "        _str = '|{}| {}%'.format(bar, percents)\n",
    "    else:\n",
    "        _str = '|{}| {}% - {}'.format(bar, percents, status)\n",
    "\n",
    "    print('\\r', end='', flush=True)\n",
    "    print(_str, end='', flush=True)\n",
    "\n",
    "\n",
    "def date_convert(table, dc):\n",
    "    for c in dc:\n",
    "        table[c] = pd.to_datetime(table[c], errors='coerce', format='%Y%m%d')\n",
    "\n",
    "\n",
    "def date_convert_back(table, dc):\n",
    "    for c in dc:\n",
    "        for index, _ in table[c].items():\n",
    "            table[c][index] = pd.Timestamp(table[c][index])\n",
    "\n",
    "\n",
    "enc_dic = {}\n",
    "\n",
    "product = pd.read_csv(product_file, sep=';', encoding='latin1').copy()\n",
    "package = pd.read_csv(package_file, sep=';', encoding='latin1').copy()\n",
    "\n",
    "# Make everything lower characters in both tables\n",
    "df_to_lower(product)\n",
    "df_to_lower(package)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Auscultation\n",
    "Nous avons déjà prétraitées les données (passage de toutes les données en minuscules) afin de minimiser l'inconsistance\n",
    "entre les valeurs.\n",
    "\n",
    "## Etude des données du fichier 'product'"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('Assessing completeness product data table')\n",
    "assert_table_completeness(product)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que la colonne PRODUCTID présente 1560 valeurs manquantes. La colonne PRODUCTNDC quant à elle présente \n",
    "certaines valeurs aberrantes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(product['PRODUCTNDC'][159:161])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la colonne PRODUCTTYPENAME, on remarque 7 valeurs possibles textuelles catégorielles dans cette colonne et aucune\n",
    "valeur manquante. Cette colonne sera donc facilement numérisable. \n",
    "\n",
    "La colonne PROPRIETARYNAME dispose d'un grand nombre de valeurs différentes, de type textuelle. Ces valeurs sont assez \n",
    "variables (phrase, simple mot) décrivant plus ou moins le produit. \n",
    "La colonne PROPRIETARYNAMESUFFIX est du même type que PROPRIETARYNAME, cependant elle présente beaucoup de valeurs \n",
    "nulles, et apporte des informations variantes aux objets. La documentation précise ne reconnait pas de standard.\n",
    "\n",
    "La colonne NONPROPRIETARYNAME présente seulement 4 valeurs manquantes mais un nombre très important de valeurs \n",
    "textuelles différentes. Elle indique les ingrédients actifs du produit, donc présente ses valeurs sous forme de liste\n",
    "(inconsistante dans sa représentation). Les valeurs manquantes paraissent difficilement remplissables.\n",
    "\n",
    "La colonne DOSAGEFORMNAME présente des données du standard FDA. En les étudiant, on se rend compte que nous pourrions \n",
    "simplifier notre utilisation du standard. En effet, celui-ci apporte une information principale sur le mode \n",
    "d'administration et présente certaines caractéristiques plus spécifique au mode. Ces dernières pourraient être omises \n",
    "pour notre utilisation car trop spécifiques et pouvant être globalisés en gardant seulement l'information principale\n",
    "du mode d'administration.\n",
    "\n",
    "La colonne ROUTENAME présente des données du standard FDA. Chaque objet a la possibilité d'en contenir plusieurs. On \n",
    "remarque que la représentation de données multiples est consistante, via un séparateur ';'. Il y a un nombre conséquent\n",
    "de données manquantes qui seront à priori difficiles à compléter.\n",
    "\n",
    "Les colonnes STARTMARKETINGDATE et ENDMARKETINGDATE sont similaires à celle présentes dans la table 'package'. \n",
    "Cependant, dans cette table, il n'y a aucune valeur manquante pour la colonne STARTMARKETINGDATE.\n",
    "nt de type date, il y a un grand nombre de valeurs manquantes. \n",
    "\n",
    "La colonne MARKETINGCATEGORYNAME présente des données du standard FDA. Il n'y a pas de valeur manquante et seulement \n",
    "10 catégories différentes, la colonne sera donc numérisables facilement. \n",
    "\n",
    "La colonne APPLICATIONNUMBER spécifie pour chaque objet le numéro de catégorie marketing associée (présente dans la \n",
    "colonne MARKETINGCATEGORYNAME). Il y a un nombre important de valeurs manquantes. \n",
    "\n",
    "La colonne LABELERNAME présente des données textuelles très inconsistantes réflétant donc le nombre important de valeurs\n",
    "différentes. Cette colonne parait difficilement numérisables et les valeurs manquantes (557) non complétables. \n",
    "\n",
    "Il appert également que, toutes colonnes confondues, les valeurs uniques sont parfois simplement des permutations de\n",
    "\"sous-valeurs\" séparées par des charctères de ponctuation ou des charctères spéciaux. Il convient donc de\n",
    "décortiquer d'avantage ces données pour réduire le nombre de catégories au maximum pour les dimensions concernées.\n",
    "Par exemple, les 180 valeurs uniques de la colonne ROUTENAME peuvent en fait être réduite à 65 \"vraies\" valeurs uniques\n",
    "lorsqu'on fait abstraction des permutations:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('Actual unique values for ROUTENAME')\n",
    "product_unique_values = get_decomposed_uniques(product, 'ROUTENAME')\n",
    "print(product_unique_values)\n",
    "\n",
    "print('Actual unique values for PHARM_CLASSES')\n",
    "product_unique_values = get_decomposed_uniques(product, 'PHARM_CLASSES')\n",
    "print(product_unique_values)\n",
    "\n",
    "print('Actual unique values for ACTIVE_INGREDIENT_UNIT')\n",
    "product_unique_values = get_decomposed_uniques(product, 'ACTIVE_INGRED_UNIT')\n",
    "print(product_unique_values)\n",
    "\n",
    "print('Actual unique values for ACTIVE_NUMERATOR_STRENGTH')\n",
    "product_unique_values = get_decomposed_uniques(product, 'ACTIVE_NUMERATOR_STRENGTH')\n",
    "print(product_unique_values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('Example of values for LABELERNAME')\n",
    "print(product['LABELERNAME'][7252:7255])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonne SUBSTANCENAME présente des données du standard FDA, celui-ci est composé de 108 227 catégories différentes.\n",
    "Chaque objet peut présenter plusieurs catégories, la représentation de valeurs multiples est consistante via le \n",
    "séparateur ';'. Cela pourrait expliquer le nombre important de valeurs différentes. Le nombre de valeurs manquantes\n",
    "est important et les valeurs seront difficilement complétables.\n",
    "\n",
    "Les colonnes ACTIVE_NUMERATOR_STRENGTH et ACTIVE_INGRED_UNIT présentent des valeurs liées à la substance. \n",
    "Il existe des valeurs multiples et une consistance dans leur représentation via le séparateur ';'. \n",
    "Le nombre de valeurs manquantes est égal pour les deux colonnes. Elles paraissent assez facilement numérisables mais \n",
    "difficilement complétables.\n",
    "\n",
    "La colonne PHARM_CLASSES présente des données du standard FDA, cependant il y en a un extrêmement important. Chaque \n",
    "objet peut disposer de plusieurs valeurs, la représentation de multiples valeurs semblent être consistante via le \n",
    "séparateur ','. \n",
    "Comme précisé par la FDA, ces données sont les catégories pharmaceutiques correspondants aux substances\n",
    "du produit (valeurs contenues dans la colonne SUBSTANCENAME). On sait cependant qu'il existe un nombre assez important \n",
    "de valeurs de noms de substances manquantes. \n",
    "\n",
    "La colonne DEASCHEDULE présente des données du standard FDA. Ces données semblent être facilement numérisables, il y\n",
    "cependant un nombre important de données manquantes qui seront difficilement complétables car nécessite de les traiter\n",
    "un à un par un expert.\n",
    "\n",
    "La colonne NDC_EXCLUDE_FLAG présente seulement la catégorie N pour notre jeu de données, comme précisé dans la \n",
    "documentation. Il n'y a pas de valeur manquante."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(product['NDC_EXCLUDE_FLAG'].value_counts())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude des données du fichier 'package'"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('Etude de la complétude des données de la table package')\n",
    "assert_table_completeness(package)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonne PRODUCTID ne présente pas de valeurs manquantes. Celle-ci fournit les valeurs concaténées de \n",
    "code produit NDC et de l'identifiant SPL. \n",
    "\n",
    "Cependant, la colonne PRODUCTNDC présente quant à elle 1500 valeurs manquantes. On remarque également des valeurs \n",
    "aberrantes dans ses valeurs.\n",
    "\n",
    "Les valeurs manquantes des colonnes STARTMARKETINGDATE et ENDMARKETINGDATE sont plus nombreuses mais semblent être non \n",
    "bloquantes. Ces deux dernières colonnes sont de type date.\n",
    "\n",
    "La colonne PACKAGEDESCRIPTION est présentée sous forme de phrase et contient de multiples informations: le type de \n",
    "volume, sa valeur et son unité. S'il existe plusieurs contenants pour un objet, ils sont concaténés par un séparateur \n",
    "'>' de manière hiérarchique.\n",
    "\n",
    "Les colonnes NDC_EXCLUDE_FLAG et SAMPLE_PACKAGE, présentant peu de valeurs différentes, et sont facilement \n",
    "traitables numériquement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Relations entre attributs\n",
    "## Informations communes\n",
    "Les colonnes 'PRODUCTID' des tables 'package' et 'product' contiennent deux informations concaténées: l'idenfiant SPL \n",
    "ainsi que le contenu de leur colonne 'PRODUCTNDC', le code label et le code segment produit.  \n",
    "Dans la documentation NDC, il est précisé que c'est pour prévenir le duplicata de lignes.\n",
    "\n",
    "La colonne 'NDCPACKAGECODE' de la table 'package' contient deux informations concaténées: le code segment du package et \n",
    "le contenu de la colonne 'PRODUCTNDC', le code label et le code segment produit.\n",
    "\n",
    "La colonne 'PACKAGEDESCRIPTION' de la table 'package' contient plusieurs informations concaténées. En plus des \n",
    "informations propres à la description du package, il y a dans la majorité des objets la valeur 'NDCPACKAGECODE' associée\n",
    ".\n",
    "\n",
    "La colonne 'APPLICATIONNUMBER' de la table 'product' présente la majorité du temps le contenu de la colonne \n",
    "'MARKETINGCATEGORYNAME' et spécifie son numéro de série.\n",
    "\n",
    "Dans les deux tables, il existe des colonnes 'STARTMARKETINGDATE',  'ENDMARKETINGDATE' et 'NDCEXLUDEDFLAG'. \n",
    "Elles semblent présenter les mêmes informations entres les tables.\n",
    "\n",
    "## Corrélation\n",
    "Comme le précise la documentation, les valeurs de l'attribut 'PHARM_CLASS' de la table produtc découlent des valeurs de \n",
    "l'attribut 'SUBSTANCENAME'. La corrélation entre ces deux attributs est donc évidente.\n",
    "\n",
    "Il semble pouvoir exister une corrélation entre les attributs 'ROUTENAME' et 'DOSAGEFORMNAME' de la table produt. En \n",
    "effet, ROUTENAME présente le mode d'administration du produit et DOSAGEFORMNAME la forme du dosage. Ces idées \n",
    "d'administration se présentent donc similaires. \n",
    "\n",
    "L'attribut MARKETINGCATEGORYNAME de la table produtct présente de manière assez générale la catégorie du produit, cela \n",
    "peut donc donner des informations sur le type de médicament, qui peut être représenté conjointement par les attributs \n",
    "PHARM_CLASSES, SUBSTANCENAME de la table product.\n",
    "\n",
    "Dans la table package, l'attribut PACKAGEDESCRIPTION fournit des informations sur les volumes des différents contenants\n",
    "du produit médicamenteux. On pourrait supposer alors une corrélation entre les modes d'administration et les formes du\n",
    "dosage (en fonction du mode d'administration, le contenant peut être plus ou moins volumineux, etc). L'attribut  \n",
    "PACKAGEDESCRIPTION de la table package pourrait être corrélé aux attributs ROUTENAME et DOSAGEFORMNAME de la table \n",
    "product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Correction des incohérences\n",
    "## Table 'product'\n",
    "Il y a de nombreux points à vérifier pour la table 'product'. \n",
    "Tout d'abord, on peut s'intéresser aux colonnes date STARTMARKETINGDATE, ENDMARKETINGDATE et \n",
    "LISTING_RECORD_CERTIFIED_THROUGH. \n",
    "On se rend compte de l'existence de données aberrantes que l'on décide d'ignorer et de supprimer leur valeur."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# conversion to datetime format\n",
    "def date_convert(table, dc):\n",
    "    for c in dc:\n",
    "        table[c] = pd.to_datetime(table[c], errors='coerce', format='%Y%m%d')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# TODO date conversion cause conflict when loading back data\n",
    "date_cols = ['STARTMARKETINGDATE', 'ENDMARKETINGDATE', 'LISTING_RECORD_CERTIFIED_THROUGH']\n",
    "date_convert(product, date_cols)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aussi, il existerait une incohérence si la date de fin de mise sur le marché est moins récente que la date de début de \n",
    "mise sur le marché."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# compare STARTMARKETINGDATE and ENDMARKETINGDATE\n",
    "nb = product[product['STARTMARKETINGDATE'] > product['ENDMARKETINGDATE']].shape[0]\n",
    "print(f\"Nombre d'incohérences entre STARTMARKETINGDATE et ENDMARKETINGDATE: {nb}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonne LISTING_RECORD_CERTIFIED_THROUGH permet de savoir si la certification du produit est expiré. On considère \n",
    "donc que le produit n'est plus à jour (et donc à supprimer de notre dataset) si la date précisée dans cette \n",
    "colonne est passée. En l'occurence, il n'y a uncun produit dont la date d'échéance est antérieure au 31 décembre 2021."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "nb = (product['LISTING_RECORD_CERTIFIED_THROUGH'] < datetime.now()).sum()\n",
    "print(f'Nombre d\\'incohérences pour l\\'attribut LISTING_RECORD_CERTIFIED_THROUGH: {nb}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonne NDC_EXCLUDE_FLAG ne devrait présenter que des valeurs de la catégorie 'N' pour notre dataset, comme le \n",
    "précise la documentation FDA. On le vérifie simplement:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(product['NDC_EXCLUDE_FLAG'].value_counts())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les colonnes SUBSTANCENAME, ACTIVE_NUMERATOR_STRENGTH et ACTIVE_INGRED_UNIT présentent des valeurs multiples liées. Leur\n",
    "nombre dans chacune des colonnes doit donc être égal. On les vérifie deux à deux."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "values_count = lambda row, col: len(re.sub(r\"(\\().*?;?.*?(\\))\", '', row[col]).split(';')) if isinstance(row[col],\n",
    "                                                                                                        str) else 0\n",
    "check = lambda row: values_count(row, \"SUBSTANCENAME\") == values_count(row, \"ACTIVE_NUMERATOR_STRENGTH\") \\\n",
    "                    == values_count(row, \"ACTIVE_INGRED_UNIT\")\n",
    "nb_valid = len(product.apply(check, axis=1))\n",
    "print(f\"Nombre d'incohérences entre ces 3 colonnes: {product.shape[0] - nb_valid}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonne PRODUCTNDC présente certaines valeurs aberrantes que nous décidons de récupérer de la première\n",
    "partie de la valeur du PRODUCTID associée. En effet, celui-ci étant un duplicata, celui-ci peut être considéré comme \n",
    "correct."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print('Valeurs aberrantes dans PRODUCTNDC de la table product:')\n",
    "print(product['PRODUCTNDC'][229:233])\n",
    "\n",
    "\n",
    "def replace_outliers_productndc(table):\n",
    "    outliers = table['PRODUCTNDC'][~table['PRODUCTNDC'].str.contains(r'\\d{4,5}-\\d{3,4}', regex=True, na=False)]\n",
    "    id_outliers = table.iloc[outliers.index.values.tolist()]['PRODUCTID']\n",
    "    for (io, i) in zip(id_outliers, outliers.index.values.tolist()):\n",
    "        if not pd.isnull(io):\n",
    "            table.at[i, 'PRODUCTNDC'] = re.match('(^[^_]+)', io).group(0)\n",
    "\n",
    "\n",
    "replace_outliers_productndc(product)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certaines colonnes représentent des standards FDA, afin d'assurer aucune incohérence dans leurs valeurs, \n",
    "nous décidons de vérifier que leurs valeurs sont incluses dans les standards fournis par la FDA (disponible \n",
    "https://www.fda.gov/industry/fda-resources-data-standards/structured-product-labeling-resources). \n",
    "On s'intéressera donc aux colonnes: DOSAGEFORMNAME, ROUTENAME, MARKETINGCATEGORYNAME, DEASCHEDULE, NDC_EXCLUDE_FLAG \n",
    "Les colonnes SUBSTANCENAME et PHARM_CLASSES représentent également des standards FDA, cependant, le nombre de valeurs\n",
    "possibles fournis par la FDA est extrêment important. Nous décidons, par mesure de possibilité, ne pas les traiter."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "def check_categories(table, column_name, standard):\n",
    "    categories = pd.Series(table[column_name].unique()).dropna()\n",
    "    lowercase_standard = map(str.lower, pd.Series(standard))\n",
    "    return categories.isin(lowercase_standard).any().any()\n",
    "\n",
    "\n",
    "def check_dict_categories(table, column_name, standard):\n",
    "    categories = pd.Series(table[column_name].unique()).dropna()\n",
    "    lowercase_standard = dict((k.lower(), v.lower()) for k, v in standard.items())\n",
    "    return categories.isin(list(lowercase_standard.values())).any().any()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "cols = ['DEASCHEDULE', 'NDC_EXCLUDE_FLAG', 'ROUTENAME', 'MARKETINGCATEGORYNAME']\n",
    "standards = [standard_deaschedule, standard_ndcexcludeflag, standard_routename, standard_marketingcategoryname]\n",
    "for (col_name, stand) in zip(cols, standards):\n",
    "    check = check_categories(product, col_name, stand)\n",
    "    print(f'Toutes les valeurs de la colonne {col_name} correspondent au stardard FDA: {check}')\n",
    "\n",
    "check = check_dict_categories(product, 'DOSAGEFORMNAME', standard_dosageformname)\n",
    "print(f'Toutes les valeurs de la colonne DOSAGEFORMNAME correspondent au stardard FDA: {check}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "def check_format_standard(table, cols, reg):\n",
    "    for (c, r) in zip(cols, reg):\n",
    "        check = table[c].str.contains(r, regex=True, na=True).sum() == table.shape[0]\n",
    "        print(f'La colonne {c} répond au format de la standardisation: {check}')\n",
    "\n",
    "\n",
    "check_format_standard(product, ['PRODUCTNDC', 'PRODUCTID'], [r'\\d{4,5}-\\d{3,4}', r'\\d{4,5}-\\d{3,4}_[A-Za-z0-9\\-]+'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'attribut DOSAGEFORMNAME précise le mode d'administration utilisé pour le produit. On remarque que les différentes \n",
    "catégories spécifiées par le standard présente beaucoup d'informations qui ne semblent pas extrêmement pertinentes.\n",
    "On choisit de les résumer par leur caractéristique principale."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "standard_dosageformname_lower = dict((k.lower(), v.lower()) for k, v in standard_dosageformname.items())\n",
    "product['DOSAGEFORMNAME'] = product['DOSAGEFORMNAME'].replace(standard_dosageformname_lower)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "assert_table_completeness(product)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 'package'\n",
    "Traitement des colonnes STARTMARKETINGDATE et ENDMARKETINGDATE similairement à la table 'product'."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "date_cols = ['STARTMARKETINGDATE', 'ENDMARKETINGDATE']\n",
    "date_convert(package, date_cols)\n",
    "\n",
    "# compare STARTMARKETINGDATE and ENDMARKETINGDATE\n",
    "nb = package[package['STARTMARKETINGDATE'] > package['ENDMARKETINGDATE']].shape[0]\n",
    "print(f\"Nombre d'incohérences entre STARTMARKETINGDATE et ENDMARKETINGDATE: {nb}\")\n",
    "print(package[package['STARTMARKETINGDATE'] > package['ENDMARKETINGDATE']][['STARTMARKETINGDATE', 'ENDMARKETINGDATE']])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces anomalies semblent être valeurs aberrantes, et pourraient résulter d'une erreur manuelle.\n",
    "On décide de les remplacer par des valeurs nulles."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "package[package['STARTMARKETINGDATE'] > package['ENDMARKETINGDATE']] = pd.NaT"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonne NDC_EXCLUDE_FLAG représente un stardard FDA que l'on vérifie comme pour la table 'product'."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cols = ['NDC_EXCLUDE_FLAG']\n",
    "standards = [standard_ndcexcludeflag]\n",
    "for (col_name, stand) in zip(cols, standards):\n",
    "    check = check_categories(package, col_name, stand)\n",
    "    print(f'Toutes les valeurs de la colonne {col_name} correspondent au stardard FDA: {check}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonne PRODUCTNDC présente également des données aberrantes du même type que l'on avait trouvé dans la table product\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "replace_outliers_productndc(package)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les colonnes PRODUCTID, PRODUCTNDC et NDCPACKAGECODE suivent un format spécifié :\n",
    "- PRODUCTNDC doit répondre à une structure de digits telle que {3-5}, {3-4}, {4-4}, {4-5}.\n",
    "- PRODUCTID concatène la valeur du PRODUCTNDC et un identifiant SPL séparé par un '_'.\n",
    "- NDCPACKAGECODE concatène la valeur du PRODUCTNDC et un code segment de 2 digits séparé par '-'."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cols = ['PRODUCTNDC', 'PRODUCTID', 'NDCPACKAGECODE']\n",
    "reg = [r'\\d{4,5}-\\d{3,4}', r'\\d{4,5}-\\d{3,4}_[A-Za-z0-9\\-]+', r'\\d{4,5}-\\d{3,4}-\\d{1,2}']\n",
    "check_format_standard(package, cols, reg)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que les valeurs de la colonne NDCPACKAGECODE ne répondent pas toutes au format de la standardisation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "val_bad_formatting = package[~package['NDCPACKAGECODE'].str.contains(r'\\d{4,5}-\\d{3,4}-\\d{1,2}', regex=True, na=False)]\n",
    "val_bad_formatting['NDCPACKAGECODE']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque effectivement que certaines valeurs sont incorrectes et ne correspondent pas à des code package. On sait que\n",
    "l'attribut PACKAGEDESCRIPTION contient, pour le premier contenant, la valeur du code package. On va pouvoir le récupérer\n",
    "de cette manière."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "correct_val = val_bad_formatting['PACKAGEDESCRIPTION'].str.extract(r'\\((.*?)\\).*')\n",
    "for (i, v) in correct_val.iterrows():\n",
    "    package.at[i, 'NDCPACKAGECODE'] = v[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Données manquantes\n",
    "## Table 'package'\n",
    "Il y a des valeurs manquantes dans les colonnes NDCPACKAGECODE et PRODUCTNDC.\n",
    "Pour la colonne NDCPACKAGECODE, on peut récupérer cette information dans PACKAGEDESCRIPTION. Celle-ci se retrouve\n",
    "concaténée et associée au premier contenant du produit."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "def replace_missing_values(table, col_name_1, col_name_2, regex):\n",
    "    missing_values = package.iloc[np.where(pd.isnull(table[col_name_1]))]\n",
    "    values = missing_values[col_name_2].str.extract(regex)\n",
    "    for index, row in values.iterrows():\n",
    "        package.loc[index, col_name_1] = row[0]\n",
    "\n",
    "\n",
    "replace_missing_values(package, 'NDCPACKAGECODE', 'PACKAGEDESCRIPTION', r'\\((.*?)\\).*')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "replace_missing_values(package, 'PRODUCTNDC', 'NDCPACKAGECODE', r'^([\\w]+-[\\w]+)')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "assert_table_completeness(package)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe des valeurs manquantes pour les colonnes 'STARTMARKETINGDATE' et 'ENDMARKETINGDATE' dans la table 'package'\n",
    "mais on choisit de ne pas les compléter car on ne peut effectuer d'estimation précise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 'product'\n",
    "Un nombre conséquent de colonnes présente des valeurs manquantes. On choisit de seulement traiter la colonne PRODUCTID,\n",
    "qui sera utile lors de l'intégration des deux tables. Les autres colonnes présentent des valeurs très difficiles à\n",
    "estimer.\n",
    "\n",
    "Pour la colonne PRODUCTID, on va devoir utiliser la table package afin de pouvoir récupérer les bonnes valeurs. En\n",
    "effet, les deux tables présentent les mêmes attributs PRODUCTID et PRODUCTNDC, on peut donc se baser là-dessus pour\n",
    "retrouver les bonnes informations. Les valeurs de PRODUCTNDC étant quasiment toutes uniques, on peut considérer son\n",
    "utilisation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "missing_val = product[product['PRODUCTID'].isnull()]['PRODUCTNDC']\n",
    "values = package.loc[package['PRODUCTNDC'].isin(missing_val)]['PRODUCTID'].drop_duplicates()\n",
    "for (v, i) in zip(values, missing_val.index.values.tolist()):\n",
    "    product.at[i, 'PRODUCTID'] = v"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "assert_table_completeness(package)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Duplicata des objets\n",
    "## Table package\n",
    "On s'intéresse à la colonne NDCPACKAGECODE afin de déterminer les duplicata. En effet plusieurs packages peuvent être\n",
    "associés à un produit (PRODUCTID), cependant les code package doivent être uniques."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# tmp_prod_duplicated = product.copy()\n",
    "# tmp_prod_duplicated = tmp_prod_duplicated.dropna(axis=0, subset=['PHARM_CLASSES'])\n",
    "# tmp_prod_duplicated = tmp_prod_duplicated.reindex(index=range(tmp_prod_duplicated.shape[0]), copy=False)\n",
    "#\n",
    "# for header in product_headers_to_encode:\n",
    "#     enc_dic[header] = time_methode(onehot_encode, header, **(dict(table=tmp_prod_duplicated, header=header)))\n",
    "#     pickle.dump(enc_dic[header], open(encoder_dir + f'{header}_data_encoder.pkl', 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "package_duplicated = package[package.duplicated(['NDCPACKAGECODE'], keep=False)].copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celle-ci montre que nous avons 2 objets présentant un duplicata de code package. On les étudie deux à deux.\n",
    "### Premier duplicata"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# NaN values are set to 0 to not compromise test\n",
    "print(package_duplicated.fillna(0).iloc[0] == package_duplicated.fillna(0).iloc[1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que seules les valeurs de PRODUCTID sont différentes entre elles.\n",
    "On confirme que ces deux valeurs de PRODUCTID sont également présentes dans la table product."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "d = product.loc[product['PRODUCTID'].isin(package_duplicated.iloc[0:2]['PRODUCTID'])]\n",
    "print(d.fillna(0).iloc[0] == d.fillna(0).iloc[1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "Dans la table product, ces deux objets sont également différentes seulement pour l'attribut PRODUCTID.\n",
    "On choisit donc d'éliminer un des duplicata dans les deux tables. puisque les deux lignes dans la table product ne\n",
    "diffèrent que leurs PRODUCTID et que la portion du PRODUCTID qui suit le PRODUCTNDC est unique dans chaque cas on peut\n",
    "arbitrairement choisir de discarter la première ligne dupliquée dans chaque table.\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "product = product.drop(d.index[1])\n",
    "package = package.drop(package_duplicated.index[1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deuxième duplicata"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print(package_duplicated.fillna(0).iloc[2] == package_duplicated.fillna(0).iloc[3])\n",
    "print(package_duplicated.iloc[2:4]['STARTMARKETINGDATE'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que ces objets présentant des NDCPACKAGECODE dupliqués ont des valeurs de STARTMARKETINGDATE divergentes.\n",
    "On décide de comparer avec les objets correspondants dans la table product."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "d = product.loc[product['PRODUCTID'].isin(package_duplicated.iloc[2:3]['PRODUCTID'])]\n",
    "print(d['STARTMARKETINGDATE'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La valeur de STARTMARKETINGDATE confirme un des objets dupliqués dans package. On décide alors d'éliminer l'objet\n",
    "présentant une valeur différente de STARTMARKETINGDATE dans package."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "package = package.drop(package_duplicated.index[3])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# confirms that there are no more duplicates in package table\n",
    "d = package[package.duplicated(['NDCPACKAGECODE'], keep=False)]\n",
    "print(f'Nombre d\\'objets dupliqués dans package par rapport à NDCPACKAGECODE: {len(d)} ')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table product\n",
    "Pour la table product, on s'intéresse aux duplicata de l'attribut PRODUCTID qui devrait être unique."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# confirms that there are no more duplicates in product table\n",
    "d = product[product.duplicated(['PRODUCTID'], keep=False)]\n",
    "print(f'Nombre d\\'objets dupliqués dans product par rapport à PRODUCTID: {len(d)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs de l'attribut PRODUCTNDC devraient également être uniques entre elles.\n",
    "\"\"\"\n",
    "# %%\n",
    "\n",
    "d = product[product.duplicated(['PRODUCTNDC'], keep=False)]\n",
    "print(f'Nombre d\\'objets dupliqués dans product par rapport à PRODUCTNDC: {len(d)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Intégration des tables\n",
    "On se rend compte qu'un objet dans la table package ne dispose pas de son équivalent dans la table product. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "d = package[~package['PRODUCTID'].isin(product['PRODUCTID'])]['PRODUCTID'].values[0]\n",
    "print(f'Objet de package dont PRODUCTID est manquant dans product: {d}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On décide d'éliminer cet objet de package lors du merge, car celui-ci ne servira pas lors de l'entraînement pour le\n",
    "modèle de prédiction."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "unified_tables = pd.merge(product, package, on='PRODUCTID')\n",
    "\n",
    "print(unified_tables)\n",
    "print(assert_table_completeness(unified_tables))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les colonnes appartenant dans les deux tables unifiées sont donc à traiter. \n",
    "Pour l'attribut STARTMARKETINGDATE, on regarde que la table originale package présentait 243 valeurs manquantes, alors \n",
    "que la table originale product n'en contenait aucune. Cela se reporte donc sur les colonnes  STARTMARKETINGDATE_x et \n",
    "STARTMARKETINGDATE_y, où la deuxième présente ces valeurs manquantes. On choisit alors aisément d'éliminer \n",
    "STARTMARKETINGDATE_y au profit de l'utilisation de STARTMARKETINGDATE_x.\n",
    "Pour l'attribut ENDMARKETINGDATE, on remarque que c'est l'inverse. Par souci de logique, on choisit donc d'éliminer \n",
    "ENDMARKETINGDATE_x au profit de l'utilisation de ENDMARKETINGDATE_y."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "unified_tables = unified_tables.drop(['STARTMARKETINGDATE_y'], axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "unified_tables = unified_tables.drop(['ENDMARKETINGDATE_x'], axis=1)\n",
    "print(assert_table_completeness(unified_tables))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se souvient que tous les objets des attributs NDC_EXCLUDE_FLAG pour les deux tables sont établies à la même valeur: 'n\n",
    "'. Le choix de la colonne à garder entre NDC_EXCLUDE_FLAG_x et NDC_EXCLUDE_FLAG_y est donc peu important."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "unified_tables = unified_tables.drop(['NDC_EXCLUDE_FLAG_y'], axis=1)\n",
    "print(assert_table_completeness(unified_tables))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'intéresse maintenant à l'attribut PRODUCTNDC des deux tables:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "check = (unified_tables['PRODUCTNDC_x'] == unified_tables['PRODUCTNDC_y']).all()\n",
    "print(f'Les valeurs de l\\'attribut PRODUCTNDC_x est égal ligne par ligne aux valeurs de l\\'attribut PRODUCTNDC_y: '\n",
    "      f'{check}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ainsi éliminer l'une ou l'autre colonne sans soucis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "unified_tables = unified_tables.drop(['PRODUCTNDC_y'], axis=1)\n",
    "print(assert_table_completeness(unified_tables))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "unified_tables = unified_tables.rename(columns={'STARTMARKETINGDATE_x': 'STARTMARKETINGDATE',\n",
    "                                                'ENDMARKETINGDATE_y': 'ENDMARKETINGDATE',\n",
    "                                                'NDC_EXCLUDE_FLAG_x': 'NDC_EXCLUDE_FLAG',\n",
    "                                                'PRODUCTNDC_x': 'PRODUCTNDC'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre dataframe intitulé unified_tables possède maintenant des attributs uniques résumant au mieux les données des\n",
    " tables product et package originales.\n",
    "\n",
    "# 7. Proposition d'un ensemble d'attributs éliminant redondance \n",
    "\n",
    "L'attribut PRODUCTID concatène les valeur du code produit NDC et de l'identifiant du SPL. On peut donc éliminer \n",
    "l'information code produit NDC (déjà présent dans l'attribut PRODUCTNDC) et ainsi spécifier un attribut pour \n",
    "l'identifiant du SPL que l'on nommera SPLID.\n",
    "\n",
    "L'attribut PRODUCTNDC concatène les valeurs du code label et du code produit de segment. Ces valeurs ne sont pas \n",
    "dupliquées au sein de notre ensemble d'attributs. On peut considérer les garder également concaténées. \n",
    "\n",
    "L'attribut APPLICATIONNUMBER concatène les valeurs du nom de la catégorie marketing et de son nombre d'application.\n",
    "Etant donné que l'attribut MARKETINGCATEGORYNAME spécifie déjà uniquement le nom de la catégorie marketing, on \n",
    "considère acceptable d'éliminer la valeur du nom de la catégorie marketing de l'attribut APPLICATIONNUMBER. Le nom de\n",
    "cet attribut semble correspondre à nos nouvelles valeurs.\n",
    "\n",
    "L'attribut NDCPACKAGECODE concatène les valeurs du code label, du code produit de segment et code package de segment.\n",
    "Comme précédemment énoncé, on dispose déjà du code label et du code produit de segment dans l'attribut PRODUCTNDC. \n",
    "On peut donc éliminer ces valeurs de l'attribut NDCPACKAGECODE afin de garder seulement le code package de segment. \n",
    "Cet nouvel attribut sera nommé PACKAGECODE.\n",
    "\n",
    "L'attribut PACKAGEDESCRIPTION intègre la description de la taille et du type de package pour chacun de ses contenants.\n",
    "On y retrouve également des valeurs de NDCPACKAGECODE que l'on peut éliminer."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "def remove_content_from_attribute(attribute, regex):\n",
    "    unified_tables[attribute] = unified_tables[attribute].replace(to_replace=regex, value='', regex=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "cols = ['PRODUCTID', 'NDCPACKAGECODE', 'PACKAGEDESCRIPTION', 'APPLICATIONNUMBER']\n",
    "reg = [r'\\d{4,5}-\\d{3,4}_', r'\\d{4,5}-\\d{3,4}-', r'\\(\\d{4,5}-\\d{3,4}-\\d{2}\\) ', r'[a-zA-Z]']\n",
    "\n",
    "for (c, r) in zip(cols, reg):\n",
    "    remove_content_from_attribute(c, r)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "unified_tables = unified_tables.rename(columns={'PRODUCTID': 'SPLID',\n",
    "                                                'NDCPACKAGECODE': 'PACKAGECODE'})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "print('Voici donc notre nouvel ensemble d\\'attribut:')\n",
    "print(unified_tables.head())\n",
    "print(assert_table_completeness(unified_tables))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Proposition d'un ensemble d'attributs pour la prédiction des classes pharmaceutiques\n",
    "Comme la documentation nous l'indique, les données de l'attribut SUBSTANCENAME correspondent aux classes pharmaceutiques\n",
    ". Afin de pouvoir généraliser au mieux, on décide de se baser sur d'autres attributs. \n",
    "\n",
    "\n",
    "L'attribut SPLID sert à spécifier l'identifiant SPL, qui est un hash utilisé par la FDA pour avoir une information sur \n",
    "le document importé. Cet attribut ne nous intéresse aucunement pour la prédiction des classes pharmaceutiques.\n",
    "\n",
    "Les attributs PRODUCTNDC, PACKAGECODE sont des simplement des identifiants qui n'apportent aucune information sur des \n",
    "quelconques classes pharmaceutiques.\n",
    "\n",
    "L'attribut PRODUCTTYPENAME correspond au type de document SPL fourni à la FDA, ce qui n'est d'aucun intérêt pour \n",
    "informer sur les classes pharmaceutiques.\n",
    "\n",
    "L'attribut PROPRIETARYNAME représente le nom commercial du produit, celui-ci présente des valeurs extrêmement diverses.\n",
    "La majorité des valeurs sont douteuses quant à leur utilité pour décrire correctement le produit. On choisit de ne pas\n",
    "pouvoir en tirer parti pour nous informer sur les classes pharmaceutiques.\n",
    "\n",
    "L'attribut PROPRIETARYNAMESUFFIX représente une spécification du nom commercial du produit. Cette attribut présente \n",
    "un nombre extrêmement élevé de valeurs manquantes (159061) dont nous ne disposons pas assez d'informations pour les \n",
    "compléter. Comme nous avons éliminer l'attribut PROPRIETARYNAME dont PROPRIETARYNAMESUFFIX en ait le suffixe, par soucis\n",
    "de logique, nous décidons d'éliminer également l'attribut PROPRIETARYNAMESUFFIX.\n",
    "\n",
    "L'attribut ROUTENAME présente le mode d'administration du produit, celui-ci pourrait se révéler être lié d'une \n",
    "quelconque manière à la substance et par conséquent à une classe pharmaceutique.\n",
    "\n",
    "L'attribut DOSAGEFORMNAME représente le forme de dosage du produit, celui-ci est lié au mode d'administration. \n",
    "Pareillement, cet attribut pourrait être corrélé à la substance et donc par conséquent la classe pharmaceutique. \n",
    " \n",
    "Les attributs STARTMARKETINGDATE et ENDMARKETINGDATE présentent des informations sur les dates de mise en marché des\n",
    "produits. Cela ne nous intéresse aucunement pour déterminer les classes pharmaceutiques.\n",
    "\n",
    "L'attribut MARKETINGCATEGORYNAME et son information sur le nom de la catégorie marketing pourrait se révéler être\n",
    "informatif sur la substance du produit et donc ses classes pharmaceutiques.\n",
    "\n",
    "L'attribut APPLICATIONNUMBER représente un identifiant de la catégorie marketing, ces valeurs n'auront donc \n",
    "logiquement aucune influence sur ses classes pharmaceutiques.\n",
    "\n",
    "L'attribut LABELERNAME informe sur l'entreprise qui a créé ce produit. On considère que cela n'aura pas d'intérêt.\n",
    "\n",
    "Les attributs ACTIVE_NUMERATOR_STRENGTH et ACTIVE_INGRED_UNIT donnent les valeurs et unités des différentes substances \n",
    "du produit. Ces détails très spécifiques ne semblent pas nous intéresser pour prédirer ses classes pharmaceutiques.\n",
    "\n",
    "L'attribut DEASCHEDULE exprime le degré de dangerosité d'un produit, cette information ne semble donc pas nécessaire.\n",
    "\n",
    "L'attribut NDC_EXCLUDE_FLAG indique une information si le produit a été retiré du marché par la FDA, ce qui ne nous aide\n",
    "pas pour la prédiction des classes pharmaceutiques. \n",
    "\n",
    "L'attribut LISTING_RECORD_CERTIFIED_THROUGH donne l'information de la date de péremption du certificat du produit, nous\n",
    "décidons de ne pas le garder.\n",
    "\n",
    "Les attributs PACKAGEDESCRIPTION et SAMPLE_PACKAGE présentent des informations sur le type de contenants du produit, \n",
    "qui ne nous seront pas utile.\n",
    "\n",
    "Voici notre ensemble d'attributs choisis:\n",
    "SUBSTANCENAME, DOSAGEFORMNAME, ROUTENAME, MARKETINGCATEGORYNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation en données numériques\n",
    "Comme ce sont des données catégorielles textuelles, on décide d'utiliser un encodage one-hot pour chacun de nos \n",
    "attributs, ainsi que notre label à prédire. Or comme les valeurs de l'attribut PHARM_CLASS présentent des valeurs \n",
    "multiples, afin de sauvegarder de la mémoire, au lieu de stocker les vecteurs one hot éparses, on décide de sauvegarder\n",
    "plutôt les indexes des bits à 1."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "headers = ['SUBSTANCENAME', 'DOSAGEFORMNAME', 'ROUTENAME', 'MARKETINGCATEGORYNAME', 'PHARM_CLASSES']\n",
    "\n",
    "labelled_data = unified_tables.dropna(subset=['PHARM_CLASSES'])\n",
    "labelled_data = labelled_data[labelled_data['PHARM_CLASSES'].str.contains(r'epc', regex=True)]\n",
    "to_predict = unified_tables[unified_tables['PHARM_CLASSES'].isna()]\n",
    "\n",
    "for header in headers:\n",
    "    if not os.path.isfile(encoder_dir + f'{header}_data_encoder.pkl'):\n",
    "        enc_dic[header] = time_methode(onehot_encode, header, **(dict(table=labelled_data, header=header)))\n",
    "        pickle.dump(enc_dic[header], open(encoder_dir + f'{header}_data_encoder.pkl', 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        enc_dic[header] = pickle.load(open(encoder_dir + f'{header}_data_encoder.pkl', 'rb'))\n",
    "\n",
    "if not os.path.isfile(encoding_dir + 'unified_tables.pkl'):\n",
    "    pickle.dump(unified_tables, open(encoding_dir + 'unified_tables.pkl', 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    unified_tables = pickle.load(open(encoding_dir + 'unified_tables.pkl', 'rb'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Modèle de classification "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "def convert_scalar_to_string(table, headers):\n",
    "    for header in headers:\n",
    "        for index, value in table[header].items():\n",
    "            if isinstance(value, list):\n",
    "                table.at[index, header] = str(value).strip('[]')\n",
    "\n",
    "\n",
    "def multiple_values_to_col(table, headers):\n",
    "    for header in headers:\n",
    "        temp = table[header].str.split(r\",\", expand=True)\n",
    "        table = pd.concat([table, temp], axis=1)\n",
    "    return table\n",
    "\n",
    "\n",
    "def convert_table_indexes_scalar_to_multiple_col(table, headers):\n",
    "    convert_scalar_to_string(table, headers)\n",
    "    table = multiple_values_to_col(table, headers).drop(headers, axis=1).dropna(how='all')\n",
    "    table.fillna(value=0, inplace=True)\n",
    "    table = table.apply(pd.to_numeric)\n",
    "    return table.values\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "y_header = ['PHARM_CLASSES']\n",
    "if y_header in headers:\n",
    "    headers.remove(y_header[0])\n",
    "X_headers = headers\n",
    "\n",
    "X = labelled_data[X_headers]\n",
    "y = labelled_data[y_header]\n",
    "\n",
    "X = convert_table_indexes_scalar_to_multiple_col(X, X_headers)\n",
    "y = convert_table_indexes_scalar_to_multiple_col(y, y_header)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "classifier = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "classifier.fit(X, y)\n",
    "predictions = classifier.predict(X)\n",
    "classifier.score(X, y)\n",
    "\n",
    "score = classifier.score(X, y)\n",
    "print(f'Score : {score}')\n",
    "\n",
    "# classifier.predict(vectorizer.transform(test_data))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Conclusions\n",
    "\"\"\"\n",
    "# # TODO: CoNcLuSiOn AvEc GoOgLe"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}